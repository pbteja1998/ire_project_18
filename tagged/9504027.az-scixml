<?xml version='1.0' encoding='ISO-8859-1'?>
<!DOCTYPE PAPER SYSTEM "paper-structure.dtd">
<PAPER>
<METADATA>
<FILENO>9504027</FILENO>
<APPEARED><CONFERENCE>ACL</CONFERENCE><YEAR>1995</YEAR></APPEARED>
<CLASSIFICATION> Lg.Pr.Ap.Ot </CLASSIFICATION>
</METADATA>
<TITLE> An Efficient Generation Algorithm for Lexicalist MT </TITLE>
<AUTHORLIST>
<AUTHOR>Victor Poznanski</AUTHOR>
<AUTHOR>John L. Beaven</AUTHOR>
<AUTHOR>Pete Whitelock</AUTHOR>
</AUTHORLIST>
<ABSTRACT>
<A-S ID='A-0' AZ='OTH'> The lexicalist approach to Machine Translation offers significant advantages in the development of linguistic descriptions . </A-S>
<A-S ID='A-1' DOCUMENTC='S-16' AZ='CTR'> However , the Shake-and-Bake generation algorithm of <REF TYPE='A' SELF="YES">Whitelock 1992</REF> is NP-complete . </A-S>
<A-S ID='A-2' DOCUMENTC='S-17' AZ='AIM'> We present a polynomial time algorithm for lexicalist MT generation provided that sufficient information can be transferred to ensure more determinism . </A-S>
</ABSTRACT>
<BODY>
<DIV DEPTH='1'>
<HEADER ID='H-0'> Introduction </HEADER>
<P>
<S ID='S-0' AZ='OTH'> Lexicalist approaches to MT , particularly those incorporating the technique of Shake-and-Bake generation <REF SELF="YES" TYPE='P'>Beaven 1992a</REF> , <REF TYPE='P' SELF="YES">Beaven 1992b</REF> , <REF TYPE='P' SELF="YES">Whitelock 1994</REF> , combine the linguistic advantages of transfer <REF TYPE='P'>Arnold et al. 1988</REF> , <REF TYPE='P'>Allegranza et al. 1991</REF> and interlingual <REF TYPE='P'>Nirenburg et al. 1992</REF> , <REF TYPE='P'>Dorr 1993</REF> approaches . </S>
<S ID='S-1' AZ='CTR'> Unfortunately , the generation algorithms described to date have been intractable . </S>
<S ID='S-2' AZ='AIM'> In this paper , we describe an alternative generation component which has polynomial time complexity . </S>
</P>
<P>
<S ID='S-3' AZ='OTH'> Shake-and-Bake translation assumes a source grammar , a target grammar and a bilingual dictionary which relates translationally equivalent sets of lexical signs , carrying across the semantic dependencies established by the source language analysis stage into the target language generation stage . </S>
</P>
<P>
<S ID='S-4' AZ='OTH'> The translation process consists of three phases : </S>
</P>
<P>
<S ID='S-5' AZ='OTH'> A parsing phase , which outputs a multiset , or bag , of source language signs instantiated with sufficiently rich linguistic information established by the parse to ensure adequate translations . </S>
</P>
<P>
<S ID='S-6' AZ='OTH'> A lexical-semantic transfer phase which employs the bilingual dictionary to map the bag of instantiated source signs onto a bag of target language signs . </S>
</P>
<P>
<S ID='S-7' AZ='OTH'> A generation phase which imposes an order on the bag of target signs which is guaranteed grammatical according to the monolingual target grammar . </S>
<S ID='S-8' AZ='OTH'> This ordering must respect the linguistic constraints which have been transferred into the target signs . </S>
</P>
<P>
<S ID='S-9' AZ='OTH'> The Shake-and-Bake generation algorithm of <REF TYPE='A' SELF="YES">Whitelock 1992</REF> combines target language signs using the technique known as generate-and-test . </S>
<S ID='S-10' AZ='OTH'> In effect , an arbitrary permutation of signs is input to a shift-reduce parser which tests them for grammatical well-formedness . </S>
<S ID='S-11' AZ='OTH'> If they are well-formed , the system halts indicating success . </S>
<S ID='S-12' AZ='OTH'> If not , another permutation is tried and the process repeated . </S>
<S ID='S-13' AZ='OTH'> The complexity of this algorithm is O(n!) because all permutations ( n! for an input of size n ) may have to be explored to find the correct answer , and indeed must be explored in order to verify that there is no answer . </S>
</P>
<P>
<S ID='S-14' AZ='OTH'> Proponents of the Shake-and-Bake approach have employed various techniques to improve generation efficiency . </S>
<S ID='S-15' AZ='OTH'> For example , <REF TYPE='A' SELF="YES">Beaven 1992a</REF> employs a chart to avoid recalculating the same combinations of signs more than once during testing , and <REF TYPE='A'>Popowich 1994</REF> proposes a more general technique for storing which rule applications have been attempted ; <REF TYPE='A'>Brew 1992</REF> avoids certain pathological cases by employing global constraints on the solution space ; researchers such as <REF TYPE='A'>Brown et al. 1990</REF> and <REF TYPE='A'>Chen and Lee 1994</REF> provide a system for bag generation that is heuristically guided by probabilities . </S>
<S ID='S-16' ABSTRACTC='A-1' AZ='CTR'> However , none of these approaches is guaranteed to avoid protracted search times if an exact answer is required , because bag generation is NP-complete <REF TYPE='P'>Brew 1992</REF> . </S>
</P>
<P>
<S ID='S-17' ABSTRACTC='A-2' AZ='AIM'> Our novel generation algorithm has polynomial complexity ( <EQN/> ) . </S>
<S ID='S-18' AZ='OWN'> The reduction in theoretical complexity is achieved by placing constraints on the power of the target grammar when operating on instantiated signs , and by using a more restrictive data structure than a bag , which we call a target language normalised commutative bracketing ( TNCB ) . </S>
<S ID='S-19' AZ='OWN'> A TNCB records dominance information from derivations and is amenable to incremental updates . </S>
<S ID='S-20' AZ='OWN'> This allows us to employ a greedy algorithm to refine the structure progressively until either a target constituent is found and generation has succeeded or no more changes can be made and generation has failed . </S>
</P>
<P>
<S ID='S-21' AZ='TXT'> In the following sections , we will sketch the basic algorithm , consider how to provide it with an initial guess , and provide an informal proof of its efficiency . </S>
</P>
</DIV>
<DIV DEPTH='1'>
<HEADER ID='H-1'> A Greedy Incremental Generation Algorithm </HEADER>
<P>
<S ID='S-22' AZ='OWN'> We begin by describing the fundamentals of a greedy incremental generation algorithm . </S>
<S ID='S-23' AZ='OWN'> The crucial data structure that it employs is the TNCB . </S>
<S ID='S-24' AZ='OWN'> We give some definitions , state some key assumptions about suitable TNCBs for generation , and then describe the algorithm itself . </S>
</P>
<DIV DEPTH='2'>
<HEADER ID='H-2'> Tncbs </HEADER>
<P>
<S ID='S-25' AZ='OWN'> We assume a sign-based grammar with binary rules , each of which may be used to combine two signs by unifying them with the daughter categories and returning the mother . </S>
<S ID='S-26' AZ='OWN'> Combination is the commutative equivalent of rule application ; the linear ordering of the daughters that leads to successful rule application determines the orthography of the mother . </S>
</P>
<P>
<S ID='S-27' AZ='OTH'> <REFAUTHOR SELF="YES">Whitelock</REFAUTHOR> 's Shake-and-Bake generation algorithm attempts to arrange the bag of target signs until a grammatical ordering ( an ordering which allows all of the signs to combine to yield a single sign ) is found . </S>
<S ID='S-28' AZ='CTR'> However , the target derivation information itself is not used to assist the algorithm . </S>
<S ID='S-29' AZ='CTR'> Even in <REF TYPE='A' SELF="YES">Beaven 1992a</REF> , the derivation information is used simply to cache previous results to avoid exact recomputation at a later stage , not to improve on previous guesses . </S>
<S ID='S-30' AZ='OWN'> The reason why we believe such improvement is possible is that , given adequate information from the previous stages , two target signs cannot combine by accident ; they must do so because the underlying semantics within the signs licenses it . </S>
</P>
<P>
<S ID='S-31' AZ='OWN'> If the linguistic data that two signs contain allows them to combine , it is because they are providing a semantics which might later become more specified . </S>
<S ID='S-32' AZ='OWN'> For example , consider the bag of signs that have been derived through the Shake-and-Bake process which represent the phrase : </S>
<EXAMPLE ID='E-0'>
<EX-S> The big brown dog </EX-S>
</EXAMPLE>
</P>
<P>
<S ID='S-33' AZ='OWN'> Now , since the determiner and adjectives all modify the same noun , most grammars will allow us to construct the phrases : </S>
<EXAMPLE ID='E-1'>
<EX-S> The dog </EX-S>
<EX-S> The big dog </EX-S>
<EX-S> The brown dog </EX-S>
</EXAMPLE>
</P>
<P>
<S ID='S-34' AZ='OWN'> as well as the ` correct ' one . </S>
<S ID='S-35' AZ='CTR'> Generation will fail if all signs in the bag are not eventually incorporated in the final result , but in the naive algorithm , the intervening computation may be intractable . </S>
</P>
<P>
<S ID='S-36' AZ='OWN'> In the algorithm presented here , we start from observation that the phrases <CREF/> to <CREF/> are not incorrect semantically ; they are simply under-specifications of <CREF/> . </S>
<S ID='S-37' AZ='OWN'> We take advantage of this by recording the constituents that have combined within the TNCB , which is designed to allow further constituents to be incorporated with minimal recomputation . </S>
</P>
<P>
<S ID='S-38' AZ='OWN'> A TNCB is composed of a sign , and a history of how it was derived from its children . </S>
<S ID='S-39' AZ='OWN'> The structure is essentially a binary derivation tree whose children are unordered . </S>
<S ID='S-40' AZ='OWN'> Concretely , it is either NIL , or a triple : </S>
<IMAGE ID='I-0'/>
</P>
<P>
<S ID='S-41' AZ='OWN'> The second and third items of the TNCB triple are the child TNCBs . </S>
<S ID='S-42' AZ='OWN'> The value of a TNCB is the sign that is formed from the combination of its children , or INCONSISTENT , representing the fact that they cannot grammatically combine , or UNDETERMINED , i.e. it has not yet been established whether the signs combine . </S>
</P>
<P>
<S ID='S-43' AZ='OWN'> Undetermined TNCBs are commutative , e.g. they do not distinguish between the structures shown in Figure <CREF/> . </S>
<IMAGE ID='I-1'/>
</P>
<P>
<S ID='S-44' AZ='OWN'> In section <CREF/> we will see that this property is important when starting up the generation process . </S>
</P>
<P>
<S ID='S-45' AZ='OWN'> Let us introduce some terminology . </S>
</P>
<P>
<S ID='S-46' AZ='OWN'> A TNCB is </S>
</P>
<P>
<S ID='S-47' AZ='OWN'> well-formed iff its value is a sign , </S>
</P>
<P>
<S ID='S-48' AZ='OWN'> ill-formed iff its value is INCONSISTENT , </S>
</P>
<P>
<S ID='S-49' AZ='OWN'> undetermined ( and its value is UNDETERMINED ) iff it has not been demonstrated whether it is well-formed or ill-formed . </S>
</P>
<P>
<S ID='S-50' AZ='OWN'> maximal iff it is well-formed and its parent ( if it has one ) is ill-formed . </S>
<S ID='S-51' AZ='OWN'> In other words , a maximal TNCB is a largest well-formed component of a TNCB . </S>
<S ID='S-52' AZ='OWN'> Since TNCBs are tree-like structures , if a TNCB is undetermined or ill-formed then so are all of its ancestors ( the TNCBs that contain it ) . </S>
</P>
<P>
<S ID='S-53' AZ='OWN'> We define five operations on a TNCB . </S>
<S ID='S-54' AZ='OWN'> The first three are used to define the fourth transformation ( move ) which improves ill-formed TNCBs . </S>
<S ID='S-55' AZ='OWN'> The fifth is used to establish the well-formedness of undetermined nodes . </S>
<S ID='S-56' AZ='OWN'> In the diagrams , we use a cross to represent ill-formed nodes and a black circle to represent undetermined ones . </S>
</P>
<P>
<S ID='S-57' AZ='OWN'> Deletion : </S>
<S ID='S-58' AZ='OWN'> A maximal TNCB can be deleted from its current position . </S>
<S ID='S-59' AZ='OWN'> The structure above it must be adjusted in order to maintain binary branching . </S>
<S ID='S-60' AZ='OWN'> In figure <CREF/> , we see that when node 4 is deleted , so is its parent node 3 . </S>
<S ID='S-61' AZ='OWN'> The new node 6 , representing the combination of 2 and 5 , is marked undetermined . </S>
<IMAGE ID='I-2'/>
</P>
<P>
<S ID='S-62' AZ='OWN'> Conjunction : </S>
<S ID='S-63' AZ='OWN'> A maximal TNCB can be conjoined with another maximal TNCB if they may be combined by rule . </S>
<S ID='S-64' AZ='OWN'> In figure <CREF/> , it can be seen how the maximal TNCB composed of nodes 1 , 2 , and 3 is conjoined with the maximal TNCB composed of nodes 4 , 5 and 6 giving the TNCB made up of nodes 1 to 7 . </S>
<S ID='S-65' AZ='OWN'> The new node , 7 , is well-formed . </S>
<IMAGE ID='I-3'/>
</P>
<P>
<S ID='S-66' AZ='OWN'> Adjunction : </S>
<S ID='S-67' AZ='OWN'> A maximal TNCB can be inserted inside a maximal TNCB , i.e. conjoined with a non-maximal TNCB , where the combination is licensed by rule . </S>
<S ID='S-68' AZ='OWN'> In figure <CREF/> , the TNCB composed of nodes 1 , 2 , and 3 is inserted inside the TNCB composed of nodes 4 , 5 and 6 . </S>
<S ID='S-69' AZ='OWN'> All nodes ( only 8 in figure <CREF/> ) which dominate the node corresponding to the new combination ( node 7 ) must be marked undetermined -- such nodes are said to be disrupted . </S>
<IMAGE ID='I-4'/>
</P>
<P>
<S ID='S-70' AZ='OWN'> Movement : </S>
<S ID='S-71' AZ='OWN'> This is a combination of a deletion with a subsequent conjunction or adjunction . </S>
<S ID='S-72' AZ='OWN'> In figure <CREF/> , we illustrate a move via conjunction . </S>
<S ID='S-73' AZ='OWN'> In the left-hand figure , we assume we wish to move the maximal TNCB 4 next to the maximal TNCB 7 . </S>
<S ID='S-74' AZ='OWN'> This first involves deleting TNCB 4 ( noting it ) , and raising node 3 to replace node 2 . </S>
<S ID='S-75' AZ='OWN'> We then introduce node 8 above node 7 , and make both nodes 7 and 4 its children . </S>
<S ID='S-76' AZ='OWN'> Note that during deletion , we remove a surplus node ( node 2 in this case ) and during conjunction or adjunction we introduce a new one ( node 8 in this case ) thus maintaining the same number of nodes in the tree . </S>
<IMAGE ID='I-5'/>
</P>
<P>
<S ID='S-77' AZ='OWN'> Evaluation : </S>
<S ID='S-78' AZ='OWN'> After a movement , the TNCB is undetermined as demonstrated in figure <CREF/> . </S>
<S ID='S-79' AZ='OWN'> The signs of the affected parts must be recalculated by combining the recursively evaluated child TNCBs . </S>
</P>
</DIV>
<DIV DEPTH='2'>
<HEADER ID='H-3'> Suitable Grammars </HEADER>
<P>
<S ID='S-80' AZ='OTH'> The Shake-and-Bake system of <REF TYPE='A' SELF="YES">Whitelock 1992</REF> employs a bag generation algorithm because it is assumed that the input to the generator is no more than a collection of instantiated signs . </S>
<S ID='S-81' AZ='OTH'> Full-scale bag generation is not necessary because sufficient information can be transferred from the source language to severely constrain the subsequent search during generation . </S>
</P>
<P>
<S ID='S-82' AZ='OWN'> The two properties required of TNCBs ( and hence the target grammars with instantiated lexical signs ) are : </S>
</P>
<P>
<S ID='S-83' AZ='OWN'> Precedence Monotonicity . </S>
<S ID='S-84' AZ='OWN'> The order of the orthographies of two combining signs in the orthography of the result must be determinate -- it must not depend on any subsequent combination that the result may undergo . </S>
<S ID='S-85' AZ='OWN'> This constraint says that if one constituent fails to combine with another , no permutation of the elements making up either would render the combination possible . </S>
<S ID='S-86' AZ='OWN'> This allows bottom-up evaluation to occur in linear time . </S>
<S ID='S-87' AZ='OWN'> In practice , this restriction requires that sufficiently rich information be transferred from the previous translation stages to ensure that sign combination is deterministic . </S>
</P>
<P>
<S ID='S-88' AZ='OWN'> Dominance Monotonicity . </S>
<S ID='S-89' AZ='OWN'> If a maximal TNCB is adjoined at the highest possible place inside another TNCB , the result will be well-formed after it is re-evaluated . </S>
<S ID='S-90' AZ='OWN'> Adjunction is only attempted if conjunction fails ( in fact conjunction is merely a special case of adjunction in which no nodes are disrupted ) ; an adjunction which disrupts i nodes is attempted before one which disrupts i + 1 nodes . </S>
<S ID='S-91' AZ='OWN'> Dominance monotonicity merely requires all nodes that are disrupted under this top-down control regime to be well-formed when re-evaluated . </S>
<S ID='S-92' AZ='OWN'> We will see that this will ensure the termination of the generation algorithm within n - 1 steps , where n is the number of lexical signs input to the process . </S>
</P>
<P>
<S ID='S-93' AZ='OWN'> We are currently investigating the mathematical characterisation of grammars and instantiated signs that obey these constraints . </S>
<S ID='S-94' AZ='OWN'> So far , we have not found these restrictions particularly problematic . </S>
</P>
</DIV>
<DIV DEPTH='2'>
<HEADER ID='H-4'> The Generation Algorithm </HEADER>
<P>
<S ID='S-95' AZ='OWN'> The generator cycles through two phases : a test phase and a rewrite phase . </S>
<S ID='S-96' AZ='OWN'> Imagine a bag of signs , corresponding to `` the big brown dog barked '' , has been passed to the generation phase . </S>
<S ID='S-97' AZ='OWN'> The first step in the generation process is to convert it into some arbitrary TNCB structure , say the one in figure <CREF/> . </S>
<S ID='S-98' AZ='OWN'> In order to verify whether this structure is valid , we evaluate the TNCB . </S>
<S ID='S-99' AZ='OWN'> This is the test phase . </S>
<S ID='S-100' AZ='OWN'> If the TNCB evaluates successfully , the orthography of its value is the desired result . </S>
<S ID='S-101' AZ='OWN'> If not , we enter the rewrite phase . </S>
<IMAGE ID='I-6'/>
<S ID='S-102' AZ='OWN'> If we were continuing in the spirit of the original Shake-and-Bake generation process , we would now form some arbitrary mutation of the TNCB and retest , repeating this test-rewrite cycle until we either found a well-formed TNCB or failed . </S>
<S ID='S-103' AZ='OWN'> However , this would also be intractable due to the undirectedness of the search through the vast number of possibilities . </S>
<S ID='S-104' AZ='OWN'> Given the added derivation information contained within TNCBs and the properties mentioned above , we can direct this search by incrementally improving on previously evaluated results . </S>
</P>
<P>
<S ID='S-105' AZ='OWN'> We enter the rewrite phase , then , with an ill-formed TNCB. Each move operation must improve it . </S>
<S ID='S-106' AZ='OWN'> Let us see why this is so . </S>
</P>
<P>
<S ID='S-107' AZ='OWN'> The move operation maintains the same number of nodes in the tree . </S>
<S ID='S-108' AZ='OWN'> The deletion of a maximal TNCB removes two ill-formed nodes ( figure <CREF/> ) . </S>
<S ID='S-109' AZ='OWN'> At the deletion site , a new undetermined node is created , which may or may not be ill-formed . </S>
<S ID='S-110' AZ='OWN'> At the destination site of the movement ( whether conjunction or adjunction ) , a new well-formed node is created . </S>
</P>
<P>
<S ID='S-111' AZ='OWN'> The ancestors of the new well-formed node will be at least as well-formed as they were prior to the movement . </S>
<S ID='S-112' AZ='OWN'> We can verify this by case : </S>
</P>
<P>
<S ID='S-113' AZ='OWN'> When two maximal TNCBs are conjoined , nodes dominating the new node , which were previously ill-formed , become undetermined . </S>
<S ID='S-114' AZ='OWN'> When re-evaluated , they may remain ill-formed or some may now become well-formed . </S>
</P>
<P>
<S ID='S-115' AZ='OWN'> When we adjoin a maximal TNCB within another TNCB , nodes dominating the new well-formed node are disrupted . </S>
<S ID='S-116' AZ='OWN'> By dominance monotonicity , all nodes which were disrupted by the adjunction must become well-formed after re-evaluation . </S>
<S ID='S-117' AZ='OWN'> And nodes dominating the maximal disrupted node , which were previously ill-formed , may become well-formed after re-evaluation . </S>
</P>
<P>
<S ID='S-118' AZ='OWN'> We thus see that rewriting and re-evaluating must improve the TNCB . </S>
</P>
<P>
<S ID='S-119' AZ='OWN'> Let us further consider the contrived worst-case starting point provided in figure <CREF/> . </S>
<S ID='S-120' AZ='OWN'> After the test phase , we discover that every single interior node is ill-formed . </S>
<S ID='S-121' AZ='OWN'> We then scan the TNCB , say top-down from left to right , looking for a maximal TNCB to move . </S>
<S ID='S-122' AZ='OWN'> In this case , the first move will be PAST to bark , by conjunction ( figure <CREF/> ) . </S>
<IMAGE ID='I-7'/>
</P>
<P>
<S ID='S-123' AZ='OWN'> Once again , the test phase fails to provide a well-formed TNCB , so we repeat the rewrite phase , this time finding dog to conjoin with the ( figure <CREF/> shows the state just after the second pass through the test phase ) . </S>
<IMAGE ID='I-8'/>
</P>
<P>
<S ID='S-124' AZ='OWN'> After further testing , we again re-enter the rewrite phase and this time note that brown can be inserted in the maximal TNCB the dog barked adjoined with dog ( figure <CREF/> ) . </S>
<S ID='S-125' AZ='OWN'> Note how , after combining dog and the , the parent sign reflects the correct orthography even though they did not have the correct linear precedence . </S>
<IMAGE ID='I-9'/>
</P>
<P>
<S ID='S-126' AZ='OWN'> After finding that big may not be conjoined with the brown dog , we try to adjoin it within the latter . </S>
<S ID='S-127' AZ='OWN'> Since it will combine with brown dog , no adjunction to a lower TNCB is attempted . </S>
<IMAGE ID='I-10'/>
</P>
<P>
<S ID='S-128' AZ='OWN'> The final result is the TNCB in figure <CREF/> , whose orthography is `` the big brown dog barked '' . </S>
<IMAGE ID='I-11'/>
</P>
<P>
<S ID='S-129' AZ='OWN'> We thus see that during generation , we formed a basic constituent , the dog , and incrementally refined it by adjoining the modifiers in place . </S>
<S ID='S-130' AZ='OWN'> At the heart of this approach is that , once well-formed , constituents can only grow ; they can never be dismantled . </S>
</P>
<P>
<S ID='S-131' AZ='OWN'> Even if generation ultimately fails , maximal well-formed fragments will have been built ; the latter may be presented to the user , allowing graceful degradation of output quality . </S>
</P>
</DIV>
</DIV>
<DIV DEPTH='1'>
<HEADER ID='H-5'> Initialising the Generator </HEADER>
<P>
<S ID='S-132' AZ='OWN'> Considering the algorithm described above , we note that the number of rewrites necessary to repair the initial guess is no more than the number of ill-formed TNCBs . </S>
<S ID='S-133' AZ='OWN'> This can never exceed the number of interior nodes of the TNCB formed from n lexical signs ( i.e. n - 2 ) . </S>
<S ID='S-134' AZ='OWN'> Consequently , the better formed the initial TNCB used by the generator , the fewer the number of rewrites required to complete generation . </S>
<S ID='S-135' AZ='OWN'> In the last section , we deliberately illustrated an initial guess which was as bad as possible . </S>
<S ID='S-136' AZ='TXT'> In this section , we consider a heuristic for producing a motivated guess for the initial TNCB . </S>
</P>
<P>
<S ID='S-137' AZ='OWN'> Consider the TNCBs in figure <CREF/> . </S>
<S ID='S-138' AZ='OWN'> If we interpret the S , O and V as Subject , Object and Verb we can observe an equivalence between the structures with the bracketings : <EQN/> , <EQN/> , <EQN/> , <EQN/> .</S>
<S ID='S-139' AZ='OWN'> The implication of this equivalence is that if , say , we are translating into a <EQN/> language from a head-final language and have isomorphic dominance structures between the source and target parses , then simply mirroring the source parse structure in the initial target TNCB will provide a correct initial guess . </S>
<S ID='S-140' AZ='OWN'> For example , the English sentence <CREF/> : </S>
<EXAMPLE ID='E-2'>
<EX-S> the book is red </EX-S>
</EXAMPLE>
</P>
<P>
<S ID='S-141' AZ='OWN'> has a corresponding Japanese equivalent <CREF/> : </S>
<IMAGE ID='I-12'/>
</P>
<P>
<S ID='S-142' AZ='OWN'> If we mirror the Japanese bracketing structure in English to form the initial TNCB , we obtain : ( ( book the ) ( red is ) ) . </S>
<S ID='S-143' AZ='OWN'> This will produce the correct answer in the test phase of generation without the need to rewrite at all . </S>
</P>
<P>
<S ID='S-144' AZ='OWN'> Even if there is not an exact isomorphism between the source and target commutative bracketings , the first guess is still reasonable as long as the majority of child commutative bracketings in the target language are isomorphic with their equivalents in the source language . </S>
<S ID='S-145' AZ='OWN'> Consider the French sentence : </S>
<IMAGE ID='I-13'/>
</P>
<P>
<S ID='S-146' AZ='OWN'> The TNCB implied by the bracketing in <CREF/> is equivalent to that in figure <CREF/> and requires just one rewrite in order to make it well-formed . </S>
<S ID='S-147' AZ='OWN'> We thus see how the TNCBs can mirror the dominance information in the source language parse in order to furnish the generator with a good initial guess . </S>
<S ID='S-148' AZ='OWN'> On the other hand , no matter how the SL and TL structures differ , the algorithm will still operate correctly with polynomial complexity . </S>
<S ID='S-149' AZ='OWN'> Structural transfer can be incorporated to improve the efficiency of generation , but it is never necessary for correctness or even tractability . </S>
</P>
</DIV>
<DIV DEPTH='1'>
<HEADER ID='H-6'> The Complexity of the Generator </HEADER>
<P>
<S ID='S-150' AZ='OWN'> The theoretical complexity of the generator is <EQN/> , where n is the size of the input . </S>
<S ID='S-151' AZ='OWN'> We give an informal argument for this . </S>
<S ID='S-152' AZ='OWN'> The complexity of the test phase is the number of evaluations that have to be made . </S>
<S ID='S-153' AZ='OWN'> Each node must be tested no more than twice in the worst case ( due to precedence monotonicity ) , as one might have to try to combine its children in either direction according to the grammar rules . </S>
<S ID='S-154' AZ='OWN'> There are always exactly n - 1 non-leaf nodes , so the complexity of the test phase is O(n) . </S>
<S ID='S-155' AZ='OWN'> The complexity of the rewrite phase is that of locating the two TNCBs to be combined . </S>
<S ID='S-156' AZ='OWN'> In the worst case , we can imagine picking an arbitrary child TNCB ( O(n) ) and then trying to find another one with which it combines ( O(n) ) . </S>
<S ID='S-157' AZ='OWN'> The complexity of this phase is therefore the product of the picking and combining complexities , i.e. <EQN/> . </S>
<S ID='S-158' AZ='OWN'> The combined complexity of the test-rewrite cycle is thus <EQN/> . </S>
<S ID='S-159' AZ='OWN'> Now , in section <CREF/> , we argued that no more than n - 1 rewrites would ever be necessary , thus the overall complexity of generation ( even when no solution is found ) is <EQN/> . </S>
</P>
<P>
<S ID='S-160' AZ='OWN'> Average case complexity is dependent on the quality of the first guess , how rapidly the TNCB structure is actually improved , and to what extent the TNCB must be re-evaluated after rewriting . </S>
<S ID='S-161' AZ='OTH'> In the SLEMaT system <REF TYPE='P' SELF="YES">Poznanski et al. 1993</REF> , we have tried to form a good initial guess by mirroring the source structure in the target TNCB , and allowing some local structural modifications in the bilingual equivalences . </S>
</P>
<P>
<S ID='S-162' AZ='OWN'> Structural transfer operations only affect the efficiency and not the functionality of generation . </S>
<S ID='S-163' AZ='OWN'> Transfer specifications may be incrementally refined and empirically tested for efficiency . </S>
<S ID='S-164' AZ='OWN'> Since complete specification of transfer operations is not required for correct generation of grammatical target text , the version of Shake-and-Bake translation presented here maintains its advantage over traditional transfer models , in this respect . </S>
</P>
<P>
<S ID='S-165' AZ='OWN'> The monotonicity constraints , on the other hand , might constitute a dilution of the Shake-and-Bake ideal of independent grammars . </S>
<S ID='S-166' AZ='OWN'> For instance , precedence monotonicity requires that the status of a clause ( strictly , its lexical head ) as main or subordinate has to be transferred into German . </S>
<S ID='S-167' AZ='OWN'> It is not that the transfer of information per se compromises the ideal -- such information must often appear in transfer entries to avoid grammatical but incorrect translation ( e.g. a great man translated as un homme grand ) . </S>
<S ID='S-168' AZ='OWN'> The problem is justifying the main / subordinate distinction in every language that we might wish to translate into German . </S>
<S ID='S-169' AZ='OWN'> This distinction can be justified monolingually for the other languages that we treat ( English , French , and Japanese ) . </S>
<S ID='S-170' AZ='OWN'> Whether the constraints will ultimately require monolingual grammars to be enriched with entirely unmotivated features will only become clear as translation coverage is extended and new language pairs are added . </S>
</P>
</DIV>
<DIV DEPTH='1'>
<HEADER ID='H-7'> Conclusion </HEADER>
<P>
<S ID='S-171' AZ='AIM'> We have presented a polynomial complexity generation algorithm which can form part of any Shake-and-Bake style MT system with suitable grammars and information transfer . </S>
<S ID='S-172' AZ='OWN'> The transfer module is free to attempt structural transfer in order to produce the best possible first guess . </S>
<S ID='S-173' AZ='CTR'> We tested a TNCB-based generator in the SLEMaT MT system with the pathological cases described in <REF TYPE='A'>Brew 1992</REF> against <REFAUTHOR SELF="YES">Whitelock</REFAUTHOR> 's original generation algorithm , and have obtained speed improvements of several orders of magnitude . </S>
<S ID='S-174' AZ='OWN'> Somewhat more surprisingly , even for short sentences which were not problematic for <REFAUTHOR SELF="YES">Whitelock</REFAUTHOR> 's system , the generation component has performed consistently better . </S>
</P>
</DIV>
</BODY>
<REFERENCELIST>
<REFERENCE>
V. <SURNAME>Allegranza</SURNAME>, P. <SURNAME>Bennett</SURNAME>, J. <SURNAME>Durand</SURNAME>, F. van <SURNAME>Eynde</SURNAME>, L. <SURNAME>Humphreys</SURNAME>, P. <SURNAME>Schmidt</SURNAME>,
  and E. <SURNAME>Steiner</SURNAME>.
<DATE>1991</DATE>.
Linguistics for Machine Translation: The Eurotra Linguistic
  Specifications.
In C. Copeland, J. Durand, S. Krauwer, and B. Maegaard, editors, 
  The Eurotra Formal Specifications. Studies in Machine Translation and Natural
  Language Processing 2, pages 15-124. Office for Official Publications of
  the European Communities.
</REFERENCE>
<REFERENCE>
D. <SURNAME>Arnold</SURNAME>, S. <SURNAME>Krauwer</SURNAME>, L. des Tombe, and L. Sadler.
<DATE>1988</DATE>.
`Relaxed' Compositionality in Machine Translation.
In Second International Conference on Theoretical and
  Methodological Issues in Machine Translation of Natural Languages, Carnegie
  Mellon Univ, Pittsburgh.
</REFERENCE>
<REFERENCE>
John L. <SURNAME>Beaven</SURNAME>.
<DATE>1992a</DATE>.
Lexicalist Unification-based Machine Translation.
Ph.D. thesis, University of Edinburgh, Edinburgh.
</REFERENCE>
<REFERENCE>
John L. <SURNAME>Beaven</SURNAME>.
<DATE>1992b</DATE>.
Shake-and-Bake Machine Translation.
In Proceedings of COLING 92, pages 602-609, Nantes, France.
</REFERENCE>
<REFERENCE>
Chris <SURNAME>Brew</SURNAME>.
<DATE>1992</DATE>.
Letting the Cat out of the Bag: Generation for
  Shake-and-Bake MT.
In Proceedings of COLING 92, pages 29-34, Nantes, France.
</REFERENCE>
<REFERENCE>
Peter F. <SURNAME>Brown</SURNAME>, John <SURNAME>Cocke</SURNAME>, A Della Pietra, Vincent J. Della Pietra, Fredrick
  Jelinek, John D. Lafferty, Robert L. Mercer, and Paul S. Roossin.
<DATE>1990</DATE>.
A Statistical Approach to Machine Translation.
Computational Linguistics, 16(2):79-85, June.
</REFERENCE>
<REFERENCE>
Hsinhsi <SURNAME>Chen</SURNAME> and Yue-Shi Lee.
<DATE>1994</DATE>.
A Corrective Training Algorithm for Adaptive Learning in
  Bag Generation.
In International Conference on New Methods in Language
  Processing (NeMLaP), pages 248-254, Manchester, UK. UMIST.
</REFERENCE>
<REFERENCE>
Bonnie <SURNAME>Jean</SURNAME> Dorr.
<DATE>1993</DATE>.
Machine Translation: A View from the Lexicon.
Artificial Intelligence Series. The MIT Press, Cambridge, Mass.
</REFERENCE>
<REFERENCE>
Sergei <SURNAME>Nirenburg</SURNAME>, Jaime <SURNAME>Carbonell</SURNAME>, Masaru <SURNAME>Tomita</SURNAME>, and Kenneth <SURNAME>Goodman</SURNAME>.
<DATE>1992</DATE>.
Machine Translation: A Knowledge-Based Approach.
Morgan Kaaufmann, San Mateo, CA.
</REFERENCE>
<REFERENCE>
Fred <SURNAME>Popowich</SURNAME>.
<DATE>1994</DATE>.
Improving the Efficiency of a Generation Algorithm for
Shake and Bake Machine Translation using Head-Driven Phrase
Structure Grammar.
Technical Report CMPT-TR 94-07, School of Computing Science, Simon
Fraser University, Burnaby, British Columbia, CANADA V5A 1S6.
</REFERENCE>
<REFERENCE>
V. <SURNAME>Poznanski</SURNAME>, John L. <SURNAME>Beaven</SURNAME>, and P. <SURNAME>Whitelock</SURNAME>.
<DATE>1993</DATE>.
The Design of SLEMaT Mk II.
Technical Report IT-<DATE>1993</DATE>-19, Sharp Laboratories of Europe,
LTD, Edmund Halley Road, Oxford Science Park, Oxford OX4 4GA, July.
</REFERENCE>
<REFERENCE>
P. <SURNAME>Whitelock</SURNAME>.
<DATE>1992</DATE>.
Shake and Bake Translation.
In Proceedings of COLING 92, pages 610-616, Nantes, France.
</REFERENCE>
<REFERENCE>
P. <SURNAME>Whitelock</SURNAME>.
<DATE>1994</DATE>.
Shake-and-Bake Translation.
In C. J. Rupp, M. A. Rosner, and R. L. Johnson, editors, 
  Constraints, Language and Computation, pages 339-359. Academic Press,
  London.
</REFERENCE>
</REFERENCELIST>
</PAPER>
