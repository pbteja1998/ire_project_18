BKG	Issues in sentence categorization according to language is fundamental for NLP , especially in document processing .	A-0
BKG	In fact , with the growing amount of multilingual text corpus data becoming available , sentence categorization , leading to multilingual text structure , opens a wide range of applications in multilingual text analysis such as information retrieval or preprocessing of multilingual syntactic parser .	A-1
BKG	The major difficulties in sentence categorization are convergence and textual errors .	A-2
BKG	Convergence since dealing with short entries involve discarding languages from few clues .	A-3
BKG	Textual errors since documents coming from different electronic ways may contain spelling and grammatical errors as well as character recognition errors generated by OCR .	A-4
AIM	We describe here an approach to sentence categorization which has the originality to be based on natural properties of languages with no training set dependency .	A-5
OWN	The implementation is fast , small , robust and textual errors tolerant .	A-6
OWN	Tested for french , english , spanish and german discrimination , the system gives very interesting results , achieving in one test 99.4 % correct assignments on real sentences .	A-7
OWN	The resolution power is based on grammatical words ( not the most common words ) and alphabet .	A-8
OWN	Having the grammatical words and the alphabet of each language at its disposal , the system computes for each of them its likelihood to be selected .	A-9
OWN	The name of the language having the optimum likelihood will tag the sentence -- but non resolved ambiguities will be maintained .	A-10
OWN	We will discuss the reasons which lead us to use these linguistic facts and present several directions to improve the system 's classification performance .	A-11
OWN	Categorization sentences with linguistic properties shows that difficult problems have sometimes simple solutions .	A-12
BKG	Emergence of text categorization according to language came with the need of processing texts coming from all over the world .	S-0
BKG	The goal of text categorization is to tag texts with the name of the language in which they are written .	S-1
BKG	Information retrieval is the main application field .	S-2
OTH	To do this job , the traditionnal way is to exploit the difference between letter combinations in different languages.	S-3
OTH	For each language , the system computes from a training set a profile based on frequency ( or probability ) of letter sequences .	S-4
OTH	Then , for a given text , it computes a profile and select the language which has the closer profile .	S-5
CTR	While some text categorization systems give very good results , the major problem is that their quality is entirely based on the training set .	S-6
CTR	Profiles require a lot of data to converge and building a large representative training set is a real problem .	S-7
CTR	Moreover , this method assume that texts are monolingual and results will be affected when dealing with multilingual texts .	S-8
CTR	It does not care about natural language properties : it only considers texts as streams of characters .	S-9
CTR	There is no linguistic justification .	S-10
BKG	Today , the problem is quiet different .	S-11
BKG	Texts are more and more multilingual ( especially due to citations ) and we don't have enough tools to process them efficiently .	S-12
BKG	Tagging sentences with the name of their language solves this problem by switching each application in function of the language .	S-13
BKG	This affects the whole NLP , Information retrieval is not the only field to be concerned : syntactic analysis and every applications based on it are concerned , making study about one particular language in multilingual texts without parasitic noise is also possible .	S-14
BKG	Using the previous method is not possible because the sentence is a too small unit to converge .	S-15
BKG	The analysis method must be more precise to reveal each possible change of language .	S-16
BKG	We remark that a change of language in a text could appear at each change of sentence ( more often paragraph ) or in each included segment via quotes , parenthesis , dashes or colons .	S-17
OWN	We will call sentence the traditionnal sentence but also each segment included in it .	S-18
AIM	Studying quantities of texts , we try to understand as well as possible ways to discriminate languages .	S-19
TXT	We present in this section the results of our research which has been implemented and in the next section , other directions which seems obviously promising .	S-20
TXT	In this section , we are going to motivate the reasons which lead us to choose grammatical words as discriminant .	S-21
OWN	Grammatical words are proper to each language and are in a whole different from one language to another .	S-22
OWN	Moreover , they are short , not numerous and we can easily build an exhaustive list .	S-23
OWN	So , these words can be use as discriminant of language .	S-24
OWN	But can we use them as discriminant of sentences .	S-25
OWN	Grammatical words in sentences represent on average about 50 % of words .	S-26
OWN	They can't be omitted because they structure sentences and make them understandable .	S-27
OWN	Furthermore , relying on grammatical words allows textual errors tolerance and foreign words import from other languages ( usual in scientific texts ) .	S-28
OWN	It 's also important to note that foreign words import concerns nouns , verbs , adjectives but never grammatical words .	S-29
OWN	These rules will allow us to categorize sentences which have enough grammatical words but in short sentences ( less than 10 words ) , there are few grammatical words , and by the way , few clues .	S-30
OWN	We must introduce new knowledges to improve short sentences categorization .	S-31
OWN	To improve categorization of short sentences , a simple way is the use of the alphabet .	S-32
OWN	Alphabets are proper to each language and even if they have a great common part , some signs such as accents allows discrimination between them .	S-33
OWN	This is not the only way to improve categorization and we will see in sectionother possible issues .	S-34
OWN	It is interesting that , using these knowledges , this system will be coherent with multilingual syntactic parsers which only rely on grammatical words and endings .	S-35
OWN	So , the categorization system can constitute a switch for these parsers,.	S-36
OWN	We can also remark that using grammatical words is different from using most common words .	S-37
OWN	In fact , most common words require training set dependency and it is well known that a representative training set is very difficult to get .	S-38
OWN	The number of words to hold is quiet subjective .	S-39
OWN	Moreover , frequency is relative to texts , not to sentences .	S-40
OWN	There are two levels to improve sentences categorization : a level below using words morphology and a level above using text structure .	S-41
OWN	These improvements haven't been implemented yet and will be the object of further works .	S-42
OWN	Mainly two ways can be explore to improve categorization , using natural languages properties :	S-43
OWN	Syllabation :	S-44
OWN	the idea is to check the good syllabation of words in a language .	S-45
OWN	It requires to distinguish first , middles and last syllabs .	S-46
OWN	( Using only endings seems to be a possible way )	S-47
OWN	Sequences of voyells or consonants :	S-48
OWN	the idea is that these sequences are proper to each language .	S-49
OWN	When dealing with texts , we can also use heuristical knowledge about text structure :	S-50
OWN	In a same paragraph , contiguous sentences are written in the same language	S-51
OWN	Titles of a paragraph are written in the same language as their body	S-52
OWN	Included blocks in a sentence ( via parenthesis , ... ) are written in the same language as the sentence .	S-53
OWN	An interesting tool to build is a general document structure recognizer .	S-54
CTR	Theoritical issues in this field are in progress,but as far as we know no implementation has been done yet .	S-55
OWN	The implementation of this research can be divided in two parts : sentence tokenization and language classification .	S-56
OWN	Sentence tokenization is a problem in itsef because documents may come through different electronic ways .	S-57
OWN	Also a sentence doesn't always start with a capitalized letter and finish with a full stop ( especially in emails ) .	S-58
OWN	Texts are not formated and miscellaneous characters can be found everywhere .	S-59
OWN	Acronyms , abbreviations , full names and numbers increase the problem by inserting points and / or spaces everywhere without following any rule .	S-60
OWN	But , no rule can ever exist in free style texts .	S-61
OWN	We wrote a robust sentence parser which solves the majority of these cases , allowing us to categorize in good conditions multilingual sentences .	S-62
OWN	The realization simply implements the previous ideas .	S-63
OWN	To manage the possible points of change of language via included segments ( see section) , the language classification procedure uses a recursive algorithm to easily handle changes of context .	S-64
OWN	The classification principle is the following :	S-65
OWN	For each word of the sentence :	S-66
OWN	Checked whether the word belongs to the grammatical words list of some languages .	S-67
OWN	If so , incremented their likelihood to be selected .	S-68
OWN	Checked whether the word morphology lets think it belongs to some languages .	S-69
OWN	If so , incremented their likelihood to be selected .	S-70
OWN	Tag the sentence with the names of the languages which have the same and highest likelihood .	S-71
OWN	This algorithm has a linear complexity in time .	S-72
OWN	The test-bed set has been prepared to process French , English , Spanish and German .	S-73
OWN	We use dictionnaries to get the grammatical words of each language ( see table) and their alphabet .	S-74
OWN	We decided to use different kinds of documents to test robustness , speed , precision and textual errors tolerance .	S-75
OWN	So , we collected scientific texts , emails and novels ( see table) .	S-76
OWN	The results we obtained were expected .	S-77
OWN	They express the fact that a sentence is usually written with grammatical words and that grammatical words are totally discriminant for sentences of more than 8 words .	S-78
OWN	From 1 to 3 words , there are mainly total undeterminations .	S-79
OWN	In fact , the corpus shows that we are processing included segments ( via quotes and parenthesis ) and there are no grammatical words and few clues to rely on .	S-80
OWN	Deductions really start between 4 and 6 words .	S-81
OWN	Here , sentences and grammatical words appear but in few quantities to allow a perfect deduction .	S-82
OWN	These results show that alphabets are not good enough to discriminate short sentences .	S-83
OWN	Methods described inmust be implemented to improve results in this case .	S-84
OWN	In table, with the french corpus , the program always succeeds in isolating a single language for all the sentences containing from 8 to 125 words .	S-85
OWN	For less than 8 words there are still ambiguities or total undetermination .	S-86
OWN	Isolating a single language does not mean exactly isolating the right language .	S-87
OWN	The error rate is about 0.01 % and concerns very short sentences ( e mail where e is analysed as Spanish ) , a change of language without quotes in a sentence or an unexpected language ( the Latin Orbi et Urbi ) .	S-88
AIM	This classification method is based on texts observation and understanding of their natural properties .	S-89
OWN	It does not depend on training sets and converges fast enough to achieve very good results on sentences .	S-90
OWN	This tool is now a switch of Jacques Vergne 's multilingual syntactic parser ( for french , english and spanish ) .	S-91
OWN	The aim of this paper is also to point that the more the linguistic properties of the object are used , the best the results are .	S-92
