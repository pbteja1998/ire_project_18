{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import os\n",
    "from lxml import etree\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# globals\n",
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "\n",
    "data_file_path = \"tagged/\"\n",
    "annotated_index = \"annotated_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for reading data\n",
    "def get_lines(filename, flines):\n",
    "    lines = {}\n",
    "    with open(data_file_path + filename) as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "\n",
    "        for l in flines:\n",
    "            lines[l] = content[l+1]\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def get_doc(filename):\n",
    "    xml_file = etree.parse(data_file_path + filename)\n",
    "    doc = {\n",
    "        \"title\": \"\",\n",
    "        \"lines\": [],\n",
    "        \"file\": filename\n",
    "    }\n",
    "    \n",
    "    for elem in xml_file.iter():\n",
    "        if elem.tag == 'TITLE':\n",
    "            doc['title'] = elem.text\n",
    "        if elem.tag == 'A-S' or elem.tag == 'S' and 'AZ' in elem.attrib.keys():\n",
    "            line_dict = {\n",
    "                \"text\": elem.text.strip(),\n",
    "                \"label\": elem.attrib['AZ'],\n",
    "                \"id\": int(elem.attrib['ID'].split('-')[-1])\n",
    "            }\n",
    "            doc[\"lines\"].append(line_dict)\n",
    "    return doc\n",
    "\n",
    "def get_all_docs():\n",
    "    all_docs = []\n",
    "    files = os.listdir(data_file_path)\n",
    "    for f in files:\n",
    "        all_docs.append(get_doc(f))\n",
    "    return all_docs\n",
    "\n",
    "all_docs = get_all_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell contains methods to extract features\n",
    "def line_zone(ln):\n",
    "    \"\"\"\n",
    "    The docuement is divided into 7 zones\n",
    "    \"\"\"\n",
    "    if ln >= 0 and ln <= 20:\n",
    "        return 'A'\n",
    "    elif ln >= 21 and ln <= 40:\n",
    "        return 'B'\n",
    "    elif ln >= 41 and ln <= 60:\n",
    "        return 'C'\n",
    "    elif ln >= 61 and ln <= 80:\n",
    "        return 'D'\n",
    "    elif ln >= 81 and ln <= 100:\n",
    "        return 'E'\n",
    "    elif ln >= 101 and ln <= 120:\n",
    "        return 'F'\n",
    "    elif ln >= 121 and ln <= 140:\n",
    "        return 'G'\n",
    "    elif ln >= 141 and ln <= 160:\n",
    "        return 'H'\n",
    "    else:\n",
    "        return 'I'\n",
    "\n",
    "\n",
    "def title_word(line, title):\n",
    "    \"\"\"\n",
    "    If the line contains word appearing in the title\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    line_tokens = nltk.word_tokenize(line) \n",
    "    title_tokens = nltk.word_tokenize(title)\n",
    "    \n",
    "    filtered_line = [w for w in line_tokens if not w in stop_words] \n",
    "    filtered_title = [w for w in title_tokens if not w in stop_words]\n",
    "    \n",
    "    for w in line_tokens:\n",
    "        if w in title_tokens:\n",
    "            print(w + \" found in title \" + title)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_main_verb(line):\n",
    "    \"\"\"\n",
    "    return the main verb in a sentence\n",
    "    \"\"\"\n",
    "    doc = nlp_spacy(line)\n",
    "    for t in doc:\n",
    "        if t.dep_ == 'ROOT':\n",
    "            return t\n",
    "    # else return the first verb\n",
    "    for t in doc:\n",
    "        if t.pos_ == 'VERB':\n",
    "            return t\n",
    "    # sentence has no verb\n",
    "    return \"NoVerb\"\n",
    "\n",
    "def get_vtense(line):\n",
    "    \"\"\"\n",
    "    return the tense of main verb\n",
    "    \"\"\"\n",
    "    vrb = str(get_main_verb(line))\n",
    "    \n",
    "    if vrb == \"NoVerb\":\n",
    "        return vrb\n",
    "\n",
    "    ws = nltk.pos_tag(nltk.word_tokenize(line))\n",
    "    \n",
    "    vtag = \"\"\n",
    "    for a,b in ws:\n",
    "        if a == vrb:\n",
    "            vtag = b\n",
    "    \n",
    "    future = ['MD']\n",
    "    present = [\"VBP\", \"VBZ\",\"VBG\"]\n",
    "    past = [\"VBD\", \"VBN\"]\n",
    "    \n",
    "    if vtag in future:\n",
    "        return \"future\"\n",
    "    if vtag in present:\n",
    "        return \"present\"\n",
    "    if vtag in past:\n",
    "        return \"past\"\n",
    "    \n",
    "    return \"future\"\n",
    "\n",
    "def modal_present(line):\n",
    "    ws = nltk.pos_tag(nltk.word_tokenize(line))\n",
    "    \n",
    "    for a,b in ws:\n",
    "        if b == 'MD':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def citation(line):\n",
    "    \"\"\"\n",
    "    If the line contains any citations\n",
    "    \"\"\"\n",
    "    line = line.lower()\n",
    "    if '[' or ']' or 'cit' or 'cite' or 'extend' or 'citation':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def long_sent(line):\n",
    "    \"\"\"\n",
    "    If the sentence is long\n",
    "    \"\"\"\n",
    "    words = line.split(' ')\n",
    "    if len(words) > 20:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_feature_vector(line, title):\n",
    "    \"\"\"\n",
    "    Given a line return the corresponding feature vector\n",
    "    \"\"\"\n",
    "    lt = line['text']\n",
    "    print(lt, title)\n",
    "    fv = [line_zone(line['id']), title_word(lt, title), citation(lt), long_sent(lt),\n",
    "        modal_present(lt), get_vtense(lt)]\n",
    "    return fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An experiment designed to explore the relationship between tagging accuracy and the nature of the tagset is described , using corpora in English , French and Swedish .  Tagset Design and Inflected Languages \n",
      "and found in title  Tagset Design and Inflected Languages \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A', True, True, True, False, 'past']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now for each line in the documents we create the corresponding feature vectors matrix\n",
    "get_feature_vector(all_docs[0]['lines'][0], all_docs[0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
