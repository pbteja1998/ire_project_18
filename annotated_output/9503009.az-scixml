AIM	This paper presents an algorithm for tagging words whose part-of-speech properties are unknown .	A-0
CTR	Unlike previous work , the algorithm categorizes word tokens in context instead of word types .	A-1
OWN	The algorithm is evaluated on the Brown Corpus .	A-2
BKG	Since online text becomes available in ever increasing volumes and an ever increasing number of languages , there is a growing need for robust processing techniques that can analyze text without expensive and time-consuming adaptation to new domains and genres .	S-0
BKG	This need motivates research on fully automatic text processing that may rely on general principles of linguistics and computation , but does not depend on knowledge about individual words .	S-1
AIM	In this paper , we describe an experiment on fully automatic derivation of the knowledge necessary for part-of-speech tagging .	S-2
BKG	Part-of-speech tagging is of interest for a number of applications , for example access to text data bases, robust parsing, and general parsing,.	S-3
AIM	The goal is to find an unsupervised method for tagging that relies on general distributional properties of text , properties that are invariant across languages and sublanguages .	S-4
OWN	While the proposed algorithm is not successful for all grammatical categories , it does show that fully automatic tagging is possible when demands on accuracy are modest .	S-5
TXT	The following sections discuss related work , describe the learning procedure and evaluate it on the Brown Corpus.	S-6
OTH	The simplest part-of-speech taggers are bigram or trigram models,.	S-7
CTR	They require a relatively large tagged training text .	S-8
CTR	Transformation-based tagging as introduced byalso requires a hand-tagged text for training .	S-9
OTH	No pretagged text is necessary for Hidden Markov Models,,.	S-10
CTR	Still , a lexicon is needed that specifies the possible parts of speech for every word .	S-11
OTH	have shown that the effort necessary to construct the part-of-speech lexicon can be considerably reduced by combining learning procedures and a partial part-of-speech categorization elicited from an informant .	S-12
AIM	The present paper is concerned with tagging languages and sublanguages for which no a priori knowledge about grammatical categories is available , a situation that occurs often in practice.	S-13
OTH	Several researchers have worked on learning grammatical properties of words .	S-14
OTH	trains a connectionist net to predict words , a process that generates internal representations that reflect grammatical category .	S-15
OTH	try to infer grammatical category from bigram statistics .	S-16
OTH	anduse vector models in which words are clustered according to the similarity of their close neighbors in a corpus .	S-17
OTH	present a probabilistic model for entropy maximization that also relies on the immediate neighbors of words in a corpus .	S-18
OTH	applies factor analysis to collocations of two target words ( `` certain '' and `` right '' ) with their immediate neighbors .	S-19
CTR	What these approaches have in common is that they classify words instead of individual occurrences .	S-20
CTR	Given the widespread part-of-speech ambiguity of words this is problematic .	S-21
CTR	How should a word like `` plant '' be categorized if it has uses both as a verb and as a noun ?	S-22
CTR	How can a categorization be considered meaningful if the infinitive marker `` to '' is not distinguished from the homophonous preposition ?	S-23
OTH	In a previous paper, we trained a neural network to disambiguate part-of-speech using context ; however , no information about the word that is to be categorized was used .	S-24
CTR	This scheme fails for cases like `` The soldiers rarely come home '' vs. `` The soldiers will come home '' where the context is identical and information about the lexical item in question ( `` rarely '' vs. `` will '' ) is needed in combination with context for correct classification .	S-25
AIM	In this paper , we will compare two tagging algorithms , one based on classifying word types , and one based on classifying words-plus-context .	S-26
OWN	We start by constructing representations of the syntactic behavior of a word with respect to its left and right context .	S-27
OWN	Our working hypothesis is that syntactic behavior is reflected in co-occurrence patterns .	S-28
OWN	Therefore , we will measure the similarity between two words with respect to their syntactic behavior to , say , their left side by the degree to which they share the same neighbors on the left .	S-29
OWN	If the counts of neighbors are assembled into a vector ( with one dimension for each neighbor ) , the cosine can be employed to measure similarity .	S-30
OWN	It will assign a value close to 1.0 if two words share many neighbors , and 0.0 if they share none .	S-31
OWN	We refer to the vector of left neighbors of a word as its left context vector , and to the vector of right neighbors as its right context vector .	S-32
OWN	The unreduced context vectors in the experiment described here have 250 entries , corresponding to the 250 most frequent words in the Brown corpus .	S-33
OWN	This basic idea of measuring distributional similarity in terms of shared neighbors must be modified because of the sparseness of the data .	S-34
OWN	Consider two infrequent adjectives that happen to modify different nouns in the corpus .	S-35
OWN	Their right similarity according to the cosine measure would be zero .	S-36
OWN	This is clearly undesirable .	S-37
OWN	But even with high-frequency words , the simple vector model can yield misleading similarity measurements .	S-38
OWN	A case in point is `` a '' vs. `` an '' .	S-39
OWN	These two articles do not share any right neighbors since the former is only used before consonants and the latter only before vowels .	S-40
OWN	Yet intuitively , they are similar with respect to their right syntactic context despite the lack of common right neighbors .	S-41
OWN	Our solution to these problems is the application of a singular value decomposition .	S-42
OWN	We can represent the left vectors of all words in the corpus as a matrix C with n rows , one for each word whose left neighbors are to be represented , and k columns , one for each of the possible neighbors .	S-43
OWN	SVD can be used to approximate the row and column vectors of C in a low-dimensional space .	S-44
OWN	In more detail , SVD decomposes a matrix C , the matrix of left vectors in our case , into three matrices,, andsuch that :	S-45
OWN	is a diagonal k-by-k matrix that contains the singular values of C in descending order .	S-46
OWN	The ith singular value can be interpreted as indicating the strength of the ith principal component of C.andare orthonormal matrices that approximate the rows and columns of C , respectively .	S-47
OWN	By restricting the matrices,, andto their first m # LT k columns ( = principal components ) one obtains the matrices T , S , and D .	S-48
OWN	Their productis the best least square approximation of C by a matrix of rank m :.	S-49
OWN	We chose m = 50 ( reduction to a 50-dimensional space ) for the SVD 's described in this paper .	S-50
OWN	SVD addresses the problems of generalization and sparseness because broad and stable generalizations are represented on dimensions with large values which will be retained in the dimensionality reduction .	S-51
OWN	In contrast , dimensions corresponding to small singular values represent idiosyncrasies , like the phonological constraint on the usage of `` an '' vs. `` a '' , and will be dropped .	S-52
OWN	We also gain efficiency since we can manipulate smaller vectors , reduced to 50 dimensions .	S-53
OWN	We used SVDPACK to compute the singular value decompositions described in this paper.	S-54
OWN	Tableshows the nearest neighbors of two words ( ordered according to closeness to the head word ) after the dimensionality reduction .	S-55
OWN	Neighbors with highest similarity according to both left and right context are listed .	S-56
OWN	One can see clear differences between the nearest neighbors in the two spaces .	S-57
OWN	The right-context neighbors of `` onto '' contain verbs because both prepositions and verbs govern noun phrases to their right .	S-58
OWN	The left-context neighborhood of `` onto '' reflects the fact that prepositional phrases are used in the same position as adverbs like `` away '' and `` together '' , thus making their left context similar .	S-59
OWN	For `` seemed '' , left-context neighbors are words that have similar types of noun phrases in subject position ( mainly auxiliaries ) .	S-60
OWN	The right-context neighbors all take `` to '' - infinitives as complements .	S-61
OWN	An adjective like `` likely '' is very similar to `` seemed '' in this respect although its left context is quite different from that of `` seemed '' .	S-62
OWN	Similarly , the generalization that prepositions and transitive verbs are very similar if not identical in the way they govern noun phrases would be lost if `` left '' and `` right '' properties of words were lumped together in one representation .	S-63
OWN	These examples demonstrate the importance of representing generalizations about left and right context separately .	S-64
OWN	The left and right context vectors are the basis for four different tag induction experiments , which are described in detail below :	S-65
OWN	induction based on word type only	S-66
OWN	induction based on word type and context	S-67
OWN	induction based on word type and context , restricted to `` natural '' contexts	S-68
OWN	induction based on word type and context , using generalized left and right context vectors .	S-69
OWN	The two context vectors of a word characterize the distribution of neighboring words to its left and right .	S-70
OWN	The concatenation of left and right context vector can therefore serve as a representation of a word 's distributional behavior,.	S-71
OWN	We formed such concatenated vectors for all 47,025 words ( surface forms ) in the Brown corpus .	S-72
OWN	Here , we use the raw 250-dimensional context vectors and apply the SVD to the 47,025 - by - 500 matrix ( 47,025 words with two 250-dimensional context vectors each ) .	S-73
OWN	We obtained 47,025 50-dimensional reduced vectors from the SVD and clustered them into 200 classes using the fast clustering algorithm Buckshot( group average agglomeration applied to a sample ) .	S-74
OWN	This classification constitutes the baseline performance for distributional part-of-speech tagging .	S-75
OWN	All occurrences of a word are assigned to one class .	S-76
OWN	As pointed out above , such a procedure is problematic for ambiguous words .	S-77
OWN	In order to exploit contextual information in the classification of a token , we simply use context vectors of the two words occurring next to the token .	S-78
OWN	An occurrence of word w is represented by a concatenation of four context vectors :	S-79
OWN	The right context vector of the preceding word .	S-80
OWN	The left context vector of w .	S-81
OWN	The right context vector of w .	S-82
OWN	The left context vector of the following word .	S-83
OWN	The motivation is that a word 's syntactic role depends both on the syntactic properties of its neighbors and on its own potential for entering into syntactic relationships with these neighbors .	S-84
OWN	The only properties of context that we consider are the right-context vector of the preceding word and the left-context vector of the following word because they seem to represent the contextual information most important for the categorization of w .	S-85
OWN	For example , for the disambiguation of `` work '' in `` her work seemed to be important '' , only the fact that `` seemed '' expects noun phrases to its left is important , the right context vector of `` seemed '' does not contribute to disambiguation .	S-86
OWN	That only the immediate neighbors are crucial for categorization is clearly a simplification , but as the results presented below show it seems to work surprisingly well .	S-87
OWN	Again , an SVD is applied to address the problems of sparseness and generalization .	S-88
OWN	We randomly selected 20,000 word triplets from the corpus and formed concatenations of four context vectors as described above .	S-89
OWN	The singular value decomposition of the resulting 20,000 - by - 1,000 matrix defines a mapping from the 1,000 - dimensional space of concatenated context vectors to a 50-dimensional reduced space .	S-90
OWN	Our tag set was then induced by clustering the reduced vectors of the 20,000 selected occurrences into 200 classes .	S-91
OWN	Each of the 200 tags is defined by the centroid of the corresponding class ( the sum of its members ) .	S-92
OWN	Distributional tagging of an occurrence of a word w proceeds then by retrieving the four relevant context vectors ( right context vector of previous word , left context vector of following word , both context vectors of w ) concatenating them to one 1000-component vector , mapping this vector to 50 dimensions , computing the correlations with the 200 cluster centroids and , finally , assigning the occurrence to the closest cluster .	S-93
OWN	This procedure was applied to all tokens of the Brown corpus .	S-94
OWN	We will see below that this method of distributional tagging , although partially successful , fails for many tokens whose neighbors are punctuation marks .	S-95
OWN	The context vectors of punctuation marks contribute little information about syntactic categorization since there are no grammatical dependencies between words and punctuation marks , in contrast to strong dependencies between neighboring words .	S-96
OWN	For this reason , a second induction on the basis of word type and context was performed , but only for those tokens with informative contexts .	S-97
OWN	Tokens next to punctuation marks and tokens with rare words as neighbors were not included .	S-98
OWN	Contexts with rare words ( less than ten occurrences ) were also excluded for similar reasons : If a word only occurs nine or fewer times its left and right context vectors capture little information for syntactic categorization .	S-99
OWN	In the experiment , 20,000 natural contexts were randomly selected , processed by the SVD and clustered into 200 classes .	S-100
OWN	The classification was then applied to all natural contexts of the Brown corpus .	S-101
OWN	The context vectors used so far only capture information about distributional interactions with the 250 most frequent words .	S-102
OWN	Intuitively , it should be possible to gain accuracy in tag induction by using information from more words .	S-103
OWN	One way to do this is to let the right context vector record which classes of left context vectors occur to the right of a word .	S-104
OWN	The rationale is that words with similar left context characterize words to their right in a similar way .	S-105
OWN	For example , `` seemed '' and `` would '' have similar left contexts , and they characterize the right contexts of `` he '' and `` the firefighter '' as potentially containing an inflected verb form .	S-106
OWN	Rather than having separate entries in its right context vector for `` seemed '' , `` would '' , and `` likes '' , a word like `` he '' can now be characterized by a generalized entry for `` inflected verb form occurs frequently to my right '' .	S-107
OWN	This proposal was implemented by applying a singular value decomposition to the 47025-by - 250 matrix of left context vectors and clustering the resulting context vectors into 250 classes .	S-108
OWN	A generalized right context vector v for word w was then formed by counting how often words from these 250 classes occurred to the right of w. Entrycounts the number of times that a word from class i occurs to the right of w in the corpus ( as opposed to the number of times that the word with frequency rank i occurs to the right of w ) .	S-109
OWN	Generalized left context vectors were derived by an analogous procedure using word-based right context vectors .	S-110
OWN	Note that the information about left and right is kept separate in this computation .	S-111
CTR	This differs from previous approaches,in which left and right context vectors of a word are always used in one concatenated vector .	S-112
OWN	There are arguably fewer different types of right syntactic contexts than types of syntactic categories .	S-113
OWN	For example , transitive verbs and prepositions belong to different syntactic categories , but their right contexts are virtually identical in that they require a noun phrase .	S-114
OWN	This generalization could not be exploited if left and right context were not treated separately .	S-115
OWN	Another argument for the two-step derivation is that many words don't have any of the 250 most frequent words as their left or right neighbor .	S-116
OWN	Hence , their vector would be zero in the word-based scheme .	S-117
OWN	The class-based scheme makes it more likely that meaningful representations are formed for all words in the vocabulary .	S-118
OWN	The generalized context vectors were input to the tag induction procedure described above for word-based context vectors : 20,000 word triplets were selected from the corpus , encoded as 1,000 - dimensional vectors ( consisting of four generalized context vectors ) , decomposed by a singular value decomposition and clustered into 200 classes .	S-119
OWN	The resulting classification was applied to all tokens in the Brown corpus .	S-120
OWN	The results of the four experiments were evaluated by forming 16 classes of tags from the Penn Treebank as shown in Table.	S-121
OWN	Preliminary experiments showed that distributional methods distinguish adnominal and predicative uses of adjectives ( e.g. `` the black cat '' vs. `` the cat is black '' ) .	S-122
OWN	Therefore the tag `` ADN '' was introduced for uses of adjectives , nouns , and participles as adnominal modifiers .	S-123
OWN	The tag `` PRD '' stands for predicative uses of adjectives .	S-124
OWN	The Penn Treebank parses of the Brown corpus were used to determine whether a token functions as an adnominal modifier .	S-125
OWN	Punctuation marks , special symbols , interjections , foreign words and tags with fewer than 100 instances were excluded from the evaluation .	S-126
OWN	Tablesandpresent results for word type-based induction and induction based on word type and context .	S-127
OWN	For each tag t , the table lists the frequency of t in the corpus ( `` frequency '' ) , the number of induced tags, that were assigned to it ( `` # classes '' ) ; the number of times an occurrence of t was correctly labeled as belonging to one of( `` correct '' ) ; the number of times that a token of a different tagwas miscategorized as being an instance of( `` incorrect '' ) ; and precision and recall of the categorization of t .	S-128
OWN	Precision is the number of correct tokens divided by the sum of correct and incorrect tokens .	S-129
OWN	Recall is the number of correct tokens divided by the total number of tokens of t ( in the first column ) .	S-130
OWN	The last column gives's F measure which computes an aggregate score from precision and recall :.	S-131
OWN	We choseto give equal weight to precision and recall .	S-132
OWN	It is clear from the tables that incorporating context improves performance considerably .	S-133
OWN	The F score increases for all tags except CD , with an average improvement of more than 0.20 .	S-134
OWN	The tag CD is probably better thought of as describing a word class .	S-135
OWN	There is a wide range of heterogeneous syntactic functions of cardinals in particular contexts : quantificational and adnominal uses , bare NP 's ( `` is one of '' ) , dates and ages ( `` Jan 1 '' , `` gave his age as 25 '' ) , and enumerations .	S-136
OWN	In this light , it is not surprising that the word-type method does better on cardinals .	S-137
OWN	Tableshows that performance for generalized context vectors is better than for word-based context vectors ( 0.74 vs. 0.72 ) .	S-138
OWN	However , since the number of tags with better and worse performance is about the same ( 7 and 5 ) , one cannot conclude with certainty that generalized context vectors induce tags of higher quality .	S-139
OWN	Apparently , the 250 most frequent words capture most of the relevant distributional information so that the additional information from less frequent words available from generalized vectors only has a small effect .	S-140
OWN	Tablelooks at results for `` natural '' contexts , i.e. those not containing punctuation marks and rare words .	S-141
OWN	Performance is consistently better than for the evaluation on all contexts , indicating that the low quality of the distributional information about punctuation marks and rare words is a difficulty for successful tag induction .	S-142
OWN	Even for `` natural '' contexts , performance varies considerably .	S-143
OWN	It is fairly good for prepositions , determiners , pronouns , conjunctions , the infinitive marker , modals , and the possessive marker .	S-144
OWN	Tag induction fails for cardinals ( for the reasons mentioned above ) and for `` - ing '' forms .	S-145
OWN	Present participles and gerunds are difficult because they exhibit both verbal and nominal properties and occur in a wide variety of different contexts whereas other parts of speech have a few typical and frequent contexts .	S-146
OWN	It may seem worrying that some of the tags are assigned a high number of clusters ( e.g. , 49 for N , 36 for ADN ) .	S-147
OWN	A closer look reveals that many clusters embody finer distinctions .	S-148
OWN	Some examples : Nouns in cluster 0 are heads of larger noun phrases , whereas the nouns in cluster 1 are full-fledged NPs .	S-149
OWN	The members of classes 29 and 111 function as subjects .	S-150
OWN	Class 49 consists of proper nouns .	S-151
OWN	However , there are many pairs or triples of clusters that should be collapsed into one on linguistic grounds .	S-152
OWN	They were separated on distributional criteria that don't have linguistic correlates .	S-153
OWN	An analysis of the divergence between our classification and the manually assigned tags revealed three main sources of errors : rare words and rare syntactic phenomena , indistinguishable distribution , and non-local dependencies .	S-154
OWN	Rare words are difficult because of lack of distributional evidence .	S-155
OWN	For example , `` ties '' is used as a verb only 2 times ( out of 15 occurrences in the corpus ) .	S-156
OWN	Both occurrences are miscategorized , since its context vectors do not provide enough evidence for the verbal use .	S-157
OWN	Rare syntactic constructions pose a related problem : There are not enough instances to justify the creation of a separate cluster .	S-158
OWN	For example , verbs taking bare infinitives were classified as adverbs since this is too rare a phenomenon to provide strong distributional evidence ( `` we do not DARE speak of '' , `` legislation could HELP remove '' ) .	S-159
OWN	The case of the tags `` VBN '' and `` PRD '' ( past participles and predicative adjectives ) demonstrates the difficulties of word classes with indistinguishable distributions .	S-160
OWN	There are hardly any distributional clues for distinguishing `` VBN '' and `` PRD '' since both are mainly used as complements of `` to be '' .	S-161
OWN	A common tag class was created for `` VBN '' and `` PRD '' to show that they are reasonably well distinguished from other parts of speech , even if not from each other .	S-162
OWN	Semantic understanding is necessary to distinguish between the states described by phrases of the form `` to be adjective '' and the processes described by phrases of the form `` to be past participle '' .	S-163
OWN	Finally , the method fails if there are no local dependencies that could be used for categorization and only non-local dependencies are informative .	S-164
OWN	For example , the adverb in `` Mc * N. Hester , CURRENTLY Dean of ... '' and the conjunction in `` to add that , IF United States policies ... '' have similar immediate neighbors ( comma , NP ) .	S-165
OWN	The decision to consider only immediate neighbors is responsible for this type of error since taking a wider context into account would disambiguate the parts of speech in question .	S-166
OWN	There are three avenues of future research we are interested in pursuing .	S-167
OWN	First , we are planning to apply the algorithm to an as yet untagged language .	S-168
OWN	Languages with a rich morphology may be more difficult than English since with fewer tokens per type , there is less data on which to base a categorization decision .	S-169
OWN	Secondly , the error analysis suggests that considering non-local dependencies would improve results .	S-170
OWN	Categories that can be induced well ( those characterized by local dependencies ) could be input into procedures that learn phrase structure,.	S-171
OWN	These phrase constraints could then be incorporated into the distributional tagger to characterize non-local dependencies .	S-172
OWN	Finally , our procedure induces a `` hard '' part-of-speech classification of occurrences in context , i.e. , each occurrence is assigned to only one category .	S-173
OWN	It is by no means generally accepted that such a classification is linguistically adequate .	S-174
OWN	There is both synchronicand diachronicevidence suggesting that words and their uses can inherit properties from several prototypical syntactic categories .	S-175
OWN	For example , `` fun '' in `` It 's a fun thing to do . '' has properties of both a noun and an adjective ( superlative `` funnest '' possible ) .	S-176
OWN	We are planning to explore `` soft '' classification algorithms that can account for these phenomena .	S-177
AIM	In this paper , we have attempted to construct an algorithm for fully automatic distributional tagging , using unannotated corpora as the sole source of information .	S-178
CTR	The main innovation is that the algorithm is able to deal with part-of-speech ambiguity , a pervasive phenomenon in natural language that was unaccounted for in previous work on learning categories from corpora .	S-179
OWN	The method was systematically evaluated on the Brown corpus .	S-180
OWN	Even if no automatic procedure can rival the accuracy of human tagging , we hope that the algorithm will facilitate the initial tagging of texts in new languages and sublanguages .	S-181
OWN	I am grateful for helpful comments to Steve Finch , Jan Pedersen and two anonymous reviewers ( from ACL and EACL ) .	S-182
OWN	I 'm also indebted to Michael Berry for SVDPACK and to the Penn Treebank Project for the parsed Brown corpus .	S-183
