AIM	This paper is concerned with the detection and correction of sub-sentential English text errors .	A-0
OTH	Previous spelling programs , unless restricted to a very small set of words , have operated as post-processors .	A-1
OTH	And to date , grammar checkers and other programs which deal with ill-formed input usually step directly from spelling considerations to a full-scale parse , assuming a complete sentence .	A-2
AIM	Work described below is aimed at evaluating the effectiveness of shallow ( sub-sentential ) processing and the feasibility of cooperative error checking , through building and testing appropriately an error-processing system .	A-3
AIM	A system under construction is outlined which incorporates morphological checks ( using new two-level error rules ) over a directed letter graph , tag positional trigrams and partial parsing .	A-4
OWN	Intended testing is discussed .	A-5
BKG	Unless a keyboard user is particularly proficient , a frustrating amount of time is usually spent backtracking to pick up mis-typed or otherwise mistaken input .	S-0
AIM	Work described in this paper started from an idea of an error processor that would sit on top of an editor , detecting / correcting errors just after entry , while the user continued with further text , relieved from tedious backtracking .	S-1
OWN	Hence ` co-operative ' error processing .	S-2
OWN	But if a program is to catch such errors very soon after they are entered , it will have to operate with less than the complete sentence .	S-3
AIM	Work underway focuses on shallow processing : how far error detection and correction can proceed when the system purview is set to a stretch of text which does not admit complete sentential analysis .	S-4
OTH	To date , grammar checkers and other programs which deal with illformed input usually step directly from spelling considerations to a full-scale sentence parse .	S-5
CTR	However treating the sentence as a basic unit loses meaning when the ` sentence ' is incomplete or illformed .	S-6
OWN	Shallow processing is also interesting because it should be cheaper and faster than a complete analysis of the whole sentence .	S-7
OWN	To investigate issues involved in shallow processing and cooperative error handling , the PET ( processing errors in text ) system is being built .	S-8
OWN	The focus is on these two issues ; no attempt is being made to produce a complete product .	S-9
OWN	PET operates over a shifting window of text ( it can be attached simply and asynchronously to the Emacs editor ) .	S-10
OWN	One word in this purview is in focus at a time .	S-11
OWN	PET will give one of three responses to this word ; it will accept the word , suggest a correction , or indicate that it found an error it couldn't correct .	S-12
TXT	Below follow an outline and discussion of the ( linguistic ) components of PET and discussion of testing and evaluation of the system .	S-13
BAS	The word in focus is first passed through a two-level morphological analysis stage , based on an adaption of.	S-14
OWN	Two purposes are served here : checking the word is lexical ( i.e. in the lexicon or a permissible inflection of a word in the lexicon ) and collecting the possible categories , which are represented as sets of feature specifications.	S-15
OWN	This morphological lookup operates over a character trie which has been compressed into a ( directed ) graph .	S-16
OWN	Common endings are shared and category information is stored on the first unique transition .	S-17
OWN	The advantages of this compression are that	S-18
OWN	a word / morpheme is recognised ( and category affixation ruleschecked ) as soon as the initial letters allow uniqueness , rather than at the end of the word , and	S-19
OWN	there is an immense saving of space .	S-20
OWN	There was a reduction of over half the transitions on the trie formed from the Alvey lexicon .	S-21
OWN	If the word is unknown , the system reconsiders analysis from the point where it broke down with the added possibility of an error rule .	S-22
BAS	There are currently four error rules , corresponding to the fourtransformations : omission , insertion , transposition , substitution- considered in that order.	S-23
OWN	The error rules are in two level format and integrate seamlessly into morphological analysis .	S-24
OWN	This says that any letter ( ` X ' ) can be inserted , with asterisks indicating that it can occur in any context ( compare with) .	S-25
OWN	The right hand side represents the ` error surface ' and the left hand side the surface with error removed .	S-26
OWN	If this doesn't succeed , it backtracks to try an error rule at an earlier point in the analysis .	S-27
OWN	At present it will not apply more than one error rule per word , in keeping with findings on error frequencies.	S-28
BAS	As an alternative , a program was developed which uses positional binary trigrams( p.b.t. 's ) to spot the error position and to check candidate corrections generated by reversetransformations .	S-29
OWN	This should have the advantage over the two level error rules in that it uses a good method of calculating likely error positions and because a set of correction possibilities can be generated fairly cheaply .	S-30
OWN	( Correction possibilities are ranked using frequency information onerrors and by giving preference to very common words .  )	S-31
OWN	However initial tests over a small file of constructed errors showed that the error rules did just as well ( slightly better in fact ) at choosing the ` correct correction ' .	S-32
OWN	The error rules are applied when ordinary morphological rules fail - which is usually a place p.b.t. 's would mark as in error - but the rules don't ignore error locations p.b.t. 's accept as allowable letter combinations .	S-33
OWN	Most importantly , the error rules operate over a letter graph of the lexicon , so only ever consider lexical words ( unknown letters are instantiated to the letters associated with the transition options ) .	S-34
OWN	The disadvantage remains that generating many correction possibilities ( with SICStus backtracking ) is time-consuming .	S-35
OWN	At present this phase postulates only one grapheme at a time , although all its possible categories are passed along together to later stages .	S-36
OWN	If all of these categories eventually fail analysis , backtracking to alternative correction candidates ( different graphemes ) will occur .	S-37
OWN	The Alvey features are mapped on to the CLAWS tagset used in the LOB corpus.	S-38
OWN	Tag transitions are checked against an occurrence matrix of the tagged LOB corpus using positional binary trigrams similar to those used in the spelling checks mentioned above .	S-39
OWN	Tag checks though the current set of categories stop when one category passes , but backtrack and continue if parsing then fails .	S-40
OTH	The Core Language Engine ( CLE ) is an application independent , unification based `` general purpose device for mapping between natural language sentences and logical form representations.	S-41
OTH	Its intermediate syntactic stages involve phrasal parsing followed by full syntactic analysis ( top-down , left-corner ) .	S-42
OTH	If the latter stage fails , CLE invokes partial parsing .	S-43
BAS	The phrasal phase and partial parsing have been extracted and are being adapted to the present purpose .	S-44
OWN	After mapping onto CLE tags , application of the phrasal phase , which implements bottom-up parsing , is straightforward .	S-45
OWN	CLE partial parsing , using left-corner analysis combined with top-down prediction on the results of the phrasal phase , looks for complete phrases and breaks down a wordstring into maximal segments .	S-46
OWN	For example ,produces 1 segment andproduces 4 segments - whereas `` ate the nice friendly cat would produce 1 segment .	S-47
OWN	Partial parsing needs to be adapted to support the idea of the PET purview ; partial parsing that accepts any string likely to constitute part of a sentence .	S-48
OWN	To achieve this the ends of the wordstring delimited by the purview need to be treated differently .	S-49
OWN	On the right hand end , ` can start rule ' possibilities of words can be considered , using the prediction facility already built into the parsing process .	S-50
OWN	The left hand side could be treated by ` can end ' possibilities , but a better idea should be to keep within the purview ( ` remember ' ) previously derived constituents that involve current words .	S-51
OWN	There is a phase to be added after detection of a tag or partial parsing error .	S-52
OWN	Currently processing will just backtrack to the intraword correction level , but particularly if there has been no correction yet made , PET should consider here the possibility of a simple phrase error .	S-53
OWN	Examples are word doubling and omission of a common function word .	S-54
OWN	transformations involving the space character ( e.g. splitting a word ) have not been implemented yet .	S-55
OWN	Handling deletion of a space , or substitution of another character for a space , are straightforward additions to the morphological process .	S-56
OWN	Transposition of a space could be dealt with by setting up an expectation upon discovering deletion of the last character of a word that the ` deleted ' character may be attached to the beginning of the next word .	S-57
OWN	Addition of a space is trickier because of the focus on the word as a processing unit , e.g. corrections for `` the re could include `` there or `` the red , but the present system will not generate the former possibility .	S-58
OWN	At present the word in focus is always the newest word in the purview .	S-59
OWN	Altering this would provide some right hand context information , which would among other things facilitate handling space addition .	S-60
OWN	Allowing this change would necessitate a more complex backtracking mechanism , as there would be a focus lag between morphological processing and later phases .	S-61
OWN	It would be sensible to keep a reference to the wider context , i.e. be able to refer to earlier detections / corrections .	S-62
OWN	With respect to the editor that PET is attached to , this could correspond to a log of errors already encountered in the file being edited .	S-63
OWN	A recent Microsoft product keeps a record of personal habitual mistakes .	S-64
OWN	Either could be a valuable aid in choosing the correct correction .	S-65
OWN	The system could possibly make better use of the graph state of its lexicon .	S-66
OWN	Word transformation implies either implicit or explicit string comparison .	S-67
OWN	The advantage of a graph over a trie is that it allows for comparison from the end of the word and well as the beginning .	S-68
OWN	With the aim of evaluating the effectiveness of shallow processing , tests will be carried out to see what proportion of different types of errors can be dealt with elegantly , adequately and / or efficiently .	S-69
OWN	Under examination will be the number of errors missed / caught and wrongly / rightly corrected .	S-70
OWN	Different components and configurations of the system will be compared , for example the error rules v. p.b.t. 's .	S-71
OWN	Parameters of the system will be varied , for example the breadth of the purview , the position of the purview focus , the number of correction candidates and the timing of their generation .	S-72
OWN	Will shallow processing miss too many of the errors cooperative error processing is aimed at ?	S-73
OWN	There are two significant difficulties with collecting test data .	S-74
OWN	The central difficulty is finding a representative sample of genuine errors by native speakers , in context , with the correct version of the text attached .	S-75
OWN	Apart from anything else , ` representative ' is hard to decide - spectrum of errors or distribution of errors ?	S-76
OWN	Secondly , any corpus of text usually contains only those errors that were left undetected in the text .	S-77
OWN	Cooperative processing deals with errors that one backtracks to catch ; if not a different class or range , these at least might have a different distribution of error types .	S-78
OWN	The ideal data would be records of peoples ' keystrokes when interacting with an editor while creating or editing a piece of text .	S-79
OWN	This would allow one measure of the ( linguistic ) feasibility of cooperative error processing : the effectiveness of shallow processing over errors revealed by the keystroke-record data .	S-80
OWN	There does not appear to be an English source of this kind , so it is planned to compile one .	S-81
OWN	For comparison , a variety of other data has been collected .	S-82
OWN	Preliminary tests used generated errors , from a program that produces randomslips according to an observed distribution, using confusion matrices where appropriate.	S-83
OWN	Assembled data includes the Birkbeck corpusand multifarious misspelling lists ( without context ) .	S-84
OWN	Suggestions have been made to look for low frequency words in corpora and news / mail archives , and to the Longmans learner corpus ( not native speakers ) .	S-85
OWN	Thanks to all who offered advice on finding data , and to Dough McIlroy , Sue Blackwell and Neil Rowe for sending me their misspelling lists .	S-86
OWN	This work is supported by a British Telecom Scholarship , administered by the Cambridge Commonwealth Trust in conjunction with the Foreign and Commonwealth Office .	S-87
