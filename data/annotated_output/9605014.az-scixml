AIM	We address the problem of automatically constructing a thesaurus by clustering words based on corpus data .	A-0
BAS	We view this problem as that of estimating a joint distribution over the Cartesian product of a partition of a set of nouns and a partition of a set of verbs , and propose a learning algorithm based on the Minimum Description Length ( MDL ) Principle for such estimation .	A-1
CTR	We empirically compared the performance of our method based on the MDL Principle against the Maximum Likelihood Estimator in word clustering , and found that the former outperforms the latter .	A-2
OWN	We also evaluated the method by conducting pp-attachment disambiguation experiments using an automatically constructed thesaurus .	A-3
OWN	Our experimental results indicate that such a thesaurus can be used to improve accuracy in disambiguation .	A-4
OTH	Recently various methods for automatically constructing a thesaurus ( hierarchically clustering words ) based on corpus data have been proposed,,,.	S-0
BKG	The realization of such an automatic construction method would make it possible to	S-1
BKG	save the cost of constructing a thesaurus by hand ,	S-2
BKG	do away with subjectivity inherent in a hand made thesaurus , and	S-3
BKG	make it easier to adapt a natural language processing system to a new domain .	S-4
AIM	In this paper , we propose a new method for automatic construction of thesauri .	S-5
BAS	Specifically , we view the problem of automatically clustering words as that of estimating a joint distribution over the Cartesian product of a partition of a set of nouns ( in general , any set of words ) and a partition of a set of verbs ( in general , any set of words ) , and propose an estimation algorithm using simulated annealing with an energy function based on the Minimum Description Length ( MDL ) Principle .	S-6
OTH	The MDL Principle is a well-motivated and theoretically sound principle for data compression and estimation in information theory and statistics .	S-7
OTH	As a strategy of statistical estimation MDL is guaranteed to be near optimal .	S-8
OWN	We empirically evaluated the effectiveness of our method .	S-9
CTR	In particular , we compared the performance of an MDL-based simulated annealing algorithm in hierarchical word clustering against that of one based on the Maximum Likelihood Estimator ( MLE , for short ) .	S-10
CTR	We found that the MDL-based method performs better than the MLE-based method .	S-11
OWN	We also evaluated our method by conducting pp-attachment disambiguation experiments using a thesaurus automatically constructed by it and found that disambiguation results can be improved .	S-12
OWN	Since some words never occur in a corpus , and thus cannot be reliably classified by a method solely based on corpus data , we propose to combine the use of an automatically constructed thesaurus and a hand made thesaurus in disambiguation .	S-13
OWN	We conducted some experiments in order to test the effectiveness of this strategy .	S-14
OWN	Our experimental results indicate that combining an automatically constructed thesaurus and a hand made thesaurus widens the coverage of our disambiguation method , while maintaining high accuracy .	S-15
BKG	A method of constructing a thesaurus based on corpus data usually consists of the following three steps :	S-16
BKG	Extract co-occurrence data ( e.g. case frame data , adjacency data ) from a corpus ,	S-17
BKG	Starting from a single class ( or each word composing its own class ) , divide ( or merge ) word classes based on the co-occurrence data using some similarity ( distance ) measure .	S-18
BKG	( The former approach is called ` divisive , ' the latter ` agglomerative ' )	S-19
BKG	Repeat stepuntil some stopping condition is met , to construct a thesaurus ( tree ) .	S-20
OWN	The method we propose here consists of the same three steps .	S-21
OWN	Suppose available to us are data like those in Figure, which are frequency data ( co-occurrence data ) between verbs and their objects extracted from a corpus ( step) .	S-22
OWN	We then view the problem of clustering words as that of estimating a probabilistic model ( representing probability distribution ) that generates such data .	S-23
OWN	We assume that the target model can be defined in the following way .	S-24
OWN	First , we define a noun partitionover a given set of nounsand a verb partionover a given set of verbs.	S-25
OWN	A noun partition is any setsatisfying,and.	S-26
OWN	A verb partitionis defined analogously .	S-27
OWN	In this paper , we call a member of a noun partition a ` noun cluster , ' and a member of a verb partition a ` verb cluster ' .	S-28
OWN	We refer to a member of the Cartesian product of a noun partition and a verb partition () simply as a ` cluster ' .	S-29
OWN	We then define a probabilistic model ( a joint distribution ) , written, where random variableassumes a value from a fixed noun partition, anda value from a fixed verb partition.	S-30
OWN	Within a given cluster , we assume that each element is generated with equal probability , i.e. ,	S-31
OWN	Figureshows two example models which might have given rise to the data in Figure.	S-32
OWN	In this paper , we assume that the observed data are generated by a model belonging to the class of models just described , and select a model which best explains the data .	S-33
OWN	As a result of this , we obtain both noun clusters and verb clusters .	S-34
OWN	This problem setting is based on the intuitive assumption that similar words occur in the same context with roughly equal likelihood , as is made explicit in equation.	S-35
OWN	Thus selecting a model which best explains the given data is equivalent to finding the most appropriate classification of words based on their co-occurrence .	S-36
OWN	We now turn to the question of what strategy ( or criterion ) we should employ for estimating the best model .	S-37
BAS	Our choice is the MDL ( Minimum Description Length ) principle,,,,, a well-known principle of data compression and statistical estimation from information theory .	S-38
OTH	MDL stipulates that the best probability model for given data is that model which requires the least code length for encoding of the model itself , as well as the given data relative to it .	S-39
OWN	We refer to the code length for the model as the ` model description length ' and that for the data the ` data description length ' .	S-40
BAS	We apply MDL to the problem of estimating a model consisting of a pair of partitions as described above .	S-41
BKG	In this context , a model with less clusters , such as Model 2 in Figure, tends to be simpler ( in terms of the number of parameters ) , but also tends to have a poorer fit to the data .	S-42
BKG	In contrast , a model with more clusters , such as Model 1 in Figure, is more complex , but tends to have a better fit to the data .	S-43
BKG	Thus , there is a trade-off relationship between the simplicity of clustering ( a model ) and the goodness of fit to the data .	S-44
OTH	The model description length quantifies the simplicity ( complexity ) of a model , and the data description length quantifies the fit to the data .	S-45
OTH	According to MDL , the model which minimizes the sum total of the two types of description lengths should be selected .	S-46
TXT	In what follows , we will describe in detail how the description length is to be calculated in our current context , as well as our simulated annealing algorithm based on MDL .	S-47
TXT	We will now describe how the description length for a model is calculated .	S-48
OWN	Recall that each model is specified by the Cartesian product of a noun partition and a verb partition , and a number of parameters for them .	S-49
OWN	Here we letdenote the size of the noun partition , andthe size of the verb partition .	S-50
OWN	Then , there arefree parameters in a model .	S-51
OWN	Given a model M and data S , its total description length L ( M ) is computed as the sum of the model description length, the description length of its parameters, and the data description length.	S-52
OWN	( We often refer toas the model description length ) .	S-53
OWN	Namely ,	S-54
OWN	We employ the ` binary noun clustering method , ' in whichis fixed atand we are to decide whetheror, which is then to be applied recursively to the clusters thus obtained .	S-55
OWN	This is as if we view the nouns as entities and the verbs as features and cluster the entities based on their features .	S-56
OWN	Since there aresubsets of the set of nouns, and for each ` binary ' noun partition we have two different subsets ( a special case of which is when one subset isand the other the empty set) , the number of possible binary noun partitions is.	S-57
OWN	Thus for each binary noun partition we needbits .	S-58
OWN	Henceis calculated as	S-59
OWN	is calculated by	S-60
OWN	where | S | denotes the input data size , andis the number of ( free ) parameters in the model .	S-61
OWN	It is known that usingbits to describe each of the parameters will ( approximately ) minimize the description length.	S-62
OWN	Finally ,is calculated by	S-63
OWN	wheredenotes the observed frequency of the noun verb pair, andthe estimated probability of, which is calculated as follows	S-64
OWN	wheredenotes the observed frequency of the noun verb pairs belonging to cluster.	S-65
OWN	With the description length of a model defined in the above manner , we wish to select a model having the minimum description length and output it as the result of clustering .	S-66
OWN	Since the model description lengthis the same for each model , in practice we only need to calculate and compare.	S-67
OWN	The description lengths for the data in Figureusing the two models in Figureare shown in Table.	S-68
OWN	( Tableshows some values needed for the calculation of the description length for Model 1 . ) These calculations indicate that according to MDL , Model 1 should be selected over Model 2 .	S-69
OWN	We could in principle calculate the description length for each model and select a model with the minimum description length , if computation time were of no concern .	S-70
OWN	However , since the number of probabilistic models under consideration is exponential , this is not feasible in practice .	S-71
BAS	We employ the ` simulated annealing technique ' to deal with this problem .	S-72
OWN	Figureshows our ( divisive ) clustering algorithm .	S-73
OWN	Although there have been many methods of word clustering proposed to date , their objectives seem to vary .	S-74
OWN	In Tablewe exhibit a simple comparison between our work and related work .	S-75
BAS	Perhaps the method proposed byis the most relevant in our context .	S-76
OTH	In, they proposed a method of ` soft clustering , ' namely , each word can belong to a number of distinct classes with certain probabilities .	S-77
OTH	Soft clustering has several desirable properties .	S-78
OTH	For example , word sense ambiguities in input data can be treated in a unified manner .	S-79
CTR	Here , we restrict our attention on ` hard clustering ' ( i.e. , each word must belong to exactly one class ) , in part because we are interested in comparing the thesauri constructed by our method with existing hand-made thesauri .	S-80
OWN	( Note that a hand made thesaurus is based on hard clustering . )	S-81
TXT	In this section , we elaborate on the merits of our method .	S-82
BKG	In statistical natural language processing , usually the number of parameters in a probabilistic model to be estimated is very large , and therefore such a model is difficult to estimate with a reasonable data size that is available in practice .	S-83
BKG	( This problem is usually referred to as the ` data sparseness problem ' . )	S-84
OTH	We could smooth the estimated probabilities using an existing smoothing technique,, then calculate some similarity measure using the smoothed probabilities , and then cluster words according to it .	S-85
CTR	There is no guarantee , however , that the employed smoothing method is in any way consistent with the clustering method used subsequently .	S-86
OWN	Our method based on MDL resolves this issue in a unified fashion .	S-87
OWN	By employing models that embody the assumption that words belonging to a same cluster occur in the same context with equal likelihood , our method achieves the smoothing effect as a side effect of the clustering process , where the domains of smoothing coincide with the clusters obtained by clustering .	S-88
OWN	Thus , the coarseness or fineness of clustering also determines the degree of smoothing .	S-89
OWN	All of these effects fall out naturally as a corollary of the imperative of ` best possible estimation , ' the original motivation behind the MDL principle .	S-90
OTH	In our simulated annealing algorithm , we could alternatively employ the Maximum Likelihood Estimator ( MLE ) as criterion for the best probabilistic model , instead of MDL .	S-91
OTH	MLE , as its name suggests , selects a model which maximizes the likelihood of the data , that is ,.	S-92
OTH	This is equivalent to minimizing the ` data description length ' as defined in Section 3 , i.e..	S-93
OTH	We can see easily that MDL generalizes MLE , in that it also takes into account the complexity of the model itself .	S-94
CTR	In the presence of models with varying complexity , MLE tends to overfit the data , and output a model that is too complex and tailored to fit the specifics of the input data .	S-95
CTR	If we employ MLE as criterion in our simulated annealing algorithm , it will result in selecting a very fine model with many small clusters , most of which will have probabilities estimated as zero .	S-96
CTR	Thus , in contrast to employing MDL , it will not have the effect of smoothing at all .	S-97
CTR	Purely as a method of estimation as well , the superiority of MDL over MLE is supported by convincing theoretical findings,.	S-98
OTH	For instance , the speed of convergence of the models selected by MDL to the true model is known to be near optimal .	S-99
CTR	( The models selected by MDL converge to the true model approximately at the rate of 1 / s where s is the number of parameters in the true model , whereas for MLE the rate is 1 / t , where t is the size of the domain , or in our context , the total number of elements of. )	S-100
CTR	` Consistency ' is another desirable property of MDL , which is not shared by MLE .	S-101
OTH	That is , the number of parameters in the models selected by MDL converge to that of the true model.	S-102
OWN	Both of these properties of MDL are empirically verified in our present context , as will be shown in the next section .	S-103
CTR	In particular , we have compared the performance of employing an MDL-based simulated annealing against that of one based on MLE in word clustering .	S-104
TXT	We describe our experimental results in this section .	S-105
BKG	We compared the performance of employing MDL as a criterion in our simulated annealing algorithm , against that of employing MLE by simulation experiments .	S-106
OWN	We artificially constructed a true model of word co-occurrence , and then generated data according to its distribution .	S-107
OWN	We then used the data to estimate a model ( clustering words ) , and measured the KL distance between the true model and the estimated model .	S-108
OWN	( The algorithm used for MLE was the same as that shown in Figure, except the ` data description length ' replaces the ( total ) description length ' in Step 2 . )	S-109
OWN	Figureplots the relation between the number of obtained noun clusters ( leaf nodes in the obtained thesaurus tree ) versus the input data size , averaged over 10 trials .	S-110
OWN	( The number of noun clusters in the true model is 4 . )	S-111
OWN	Figureplots the KL distance versus the data size , also averaged over the same 10 trials .	S-112
CTR	The results indicate that MDL converges to the true model faster than MLE .	S-113
CTR	Also , MLE tends to select a model overfitting the data , while MDL tends to select a model which is simple and yet fits the data reasonably well .	S-114
OWN	We conducted the same simulation experiment for some other models and found the same tendencies .	S-115
OWN	( Figureand Figureshow the analogous results when the number of noun clusters in the true model is 2 ) .	S-116
CTR	We conclude that it is better to employ MDL than MLE in word clustering .	S-117
OWN	We extracted roughly 180,000 case frames from the bracketed WSJ ( Wall Street Journal ) corpus of the Penn Tree Bankas co-occurrence data .	S-118
OWN	We then constructed a number of thesauri based on these data , using our method .	S-119
OWN	Figureshows an example thesaurus for the 20 most frequently occurred nouns in the data , constructed based on their appearances as subject and object of roughly 2000 verbs .	S-120
OWN	The obtained thesaurus seems to agree with human intuition to some degree .	S-121
OWN	For example , ` million ' and ` billion ' are classified in one noun cluster , and ` stock ' and ` share ' are classified together .	S-122
OWN	Not all of the noun clusters , however , seem to be meaningful in the useful sense .	S-123
OWN	This is probably because the data size we had was not large enough .	S-124
OWN	This general tendency is also observed in another example thesaurus obtained by our method , shown in Figure.	S-125
OWN	Pragmatically speaking , however , whether the obtained thesaurus agrees with our intuition in itself is only of secondary concern , since the main purpose is to use the constructed thesaurus to help improve on a disambiguation task .	S-126
OWN	We also evaluated our method by using a constructed thesaurus in a pp-attachment disambiguation experiment .	S-127
OWN	We used as training data the same 180,000 case frames in Experiment 1 .	S-128
OWN	We also extracted as our test data 172patterns from the data in the same corpus , which is not used in the training data .	S-129
OWN	For the 150 words that appear in the position of, we constructed a thesaurus based on the co-occurrences between heads and slot values of the frames in the training data .	S-130
OWN	This is because in our disambiguation test we only need a thesaurus consisting of these 150 words .	S-131
BAS	We then applied the learning method proposed into learn case frame patterns with the constructed thesaurus as input using the same training data .	S-132
BAS	That is , we used it to learn the conditional distributions,, whereandvary over the internal nodes in a certain ` cut ' in the thesaurus tree .	S-133
OWN	Tableshows some example case frame patterns obtained by this method , and Figureshows the leaf nodes dominated by the internal nodes appearing in the case frame patterns of Table.	S-134
OWN	We then compareand, which are estimated based on the case frame patterns , to determine the attachment site of.	S-135
OWN	More specifically , if the former is larger than the latter , we attach it to verb , and if the latter is larger than the former , we attach it to, and otherwise ( including when both are 0 ) , we conclude that we cannot make a decision .	S-136
OWN	Tableshows the results of our pp-attachment disambiguation experiment in terms of ` coverage ' and ` accuracy ' .	S-137
OWN	Here ` coverage ' refers to the proportion ( in percentage ) of the test patterns on which the disambiguation method could make a decision .	S-138
OWN	` Base Line ' refers to the method of always attachingto.	S-139
OWN	` Word-Based , ' ` MLE-Thesaurus , ' and ` MDL-Thesaurus ' respectively stand for using word-based estimates , using a thesaurus constructed by employing MLE , and using a thesaurus constructed by our method .	S-140
CTR	Note that the coverage of ` MDL-Thesaurus ' significantly outperformed that of ` Word-Based , ' while basically maintaining high accuracy ( though it drops somewhat ) , indicating that using an automatically constructed thesaurus can improve disambiguation results in terms of coverage .	S-141
CTR	We also tested the method proposed inof learning case frames patterns using an existing thesaurus .	S-142
BAS	In particular , we used this method with WordNetand using the same training data , and then conducted pp-attachment disambiguation experiment using the obtained case frame patterns .	S-143
OWN	We show the result of this experiment as ` WordNet ' in Table.	S-144
OWN	We can see that in terms of ` coverage , ' ` WordNet ' outperforms ` MDL-Thesaurus , ' but in terms of ` accuracy , ' ` MDL-Thesaurus ' outperforms ` WordNet ' .	S-145
OWN	These results can be interpreted as follows .	S-146
OWN	An automatically constructed thesaurus is more domain dependent and captures the domain dependent features better , and thus using it achieves high accuracy .	S-147
OWN	On the other hand , since training data we had available is insufficient , its coverage is smaller than that of a hand made thesaurus .	S-148
OWN	In practice , it makes sense to combine both types of thesauri .	S-149
OWN	More specifically , an automatically constructed thesaurus can be used within its coverage , and outside its coverage , a hand made thesaurus can be used .	S-150
OWN	Given the current state of the word clustering technique ( namely , it requires data size that is usually not available , and it tends to be computationally demanding ) , this strategy is practical .	S-151
OWN	We show the result of this combined method as ` MDL-Thesaurus + WordNet ' in Table.	S-152
OWN	Our experimental result shows that employing the combined method does increase the coverage of disambiguation .	S-153
OWN	We also tested ` MDL-Thesaurus + WordNet + LA + Default , ' which stands for using the learned thesaurus and WordNet first , then the lexical association value proposed by, and finally the default ( i.e. always attachingto) .	S-154
CTR	Our best disambiguation result obtained using this last combined method somewhat improves the accuracy reported in() .	S-155
AIM	We have proposed a method of clustering words based on large corpus data .	S-156
TXT	We conclude with the following remarks .	S-157
OWN	Our method of hierarchical clustering of words based on the MDL principle is theoretically sound .	S-158
CTR	Our experimental results show that it is better to employ MDL than MLE as estimation criterion in word clustering .	S-159
OWN	Using a thesaurus constructed by our method can improve pp-attachment disambiguation results .	S-160
OWN	At the current state of the art in statistical natural language processing , it is best to use a combination of an automatically constructed thesaurus and a hand made thesaurus for disambiguation purpose .	S-161
OWN	The disambiguation accuracy obtained this way was.	S-162
OWN	In the future , hopefully with larger training data size , we plan to construct larger thesauri as well as to test other clustering algorithms .	S-163
OWN	We thank Mr. K. Nakamura , Mr. T. Fujita , and Dr. K. Kobayashi of NEC C & C Res. Labs.  for their constant encouragement .	S-164
OWN	We thank Dr. K. Yamanishi of C & C Res. Labs. for his comments .	S-165
OWN	We thank Ms. Y. Yamaguchi of NIS for her programming effort .	S-166
