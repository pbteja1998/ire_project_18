OWN	The paper demonstrates that exponential complexities with respect to grammar size and input length have little impact on the performance of three unification-based parsing algorithms , using a wide-coverage grammar .	A-0
OWN	The results imply that the study and optimisation of unification-based parsing must rely on empirical data until complexity theory can more accurately predict the practical behaviour of such parsers .	A-1
BKG	General-purpose natural language ( NL ) analysis systems have recently started to use declarative unification-based sentence grammar formalisms ; systems of this type include SRI 's CLARE systemand the Alvey NL Tools ( ANLT ).	S-0
BKG	Using a declarative formalism helps ease the task of developing and maintaining the grammar.	S-1
BKG	In addition to syntactic processing , the systems incorporate lexical , morphological , and semantic processing , and have been applied successfully to the analysis of naturally-occurring texts,.	S-2
OTH	Evaluations of the grammars in these particular systems have shown them to have wide coverage,.	S-3
CTR	However , although the practical throughput of parsers with such realistic grammars is important , for example when processing large amounts of text or in interactive applications , there is little published research that compares the performance of different parsing algorithms using wide-coverage unification-based grammars .	S-4
CTR	Previous comparisons have either focussed on context-free ( CF ) or augmented CF parsing,, or have used relatively small , limited-coverage unification grammars and lexicons,,.	S-5
CTR	It is not clear that these results scale up to reflect accurately the behaviour of parsers using realistic , complex unification-based grammars : in particular , with grammars admitting less ambiguity parse time will tend to increase more slowly with increasing input length , and also with smaller grammars rule application can be constrained tightly with relatively simple predictive techniques .	S-6
CTR	Also , since none of these studies relate observed performance to that of other comparable parsing systems , implementational oversights may not be apparent and so be a confounding factor in any general conclusions made .	S-7
OTH	Other research directed towards improving the throughput of unification-based parsing systems has been concerned with the unification operation itself , which can consume up to 90 % of parse timein systems using lexicalist grammar formalisms ( e.g. HPSG ).	S-8
CTR	However , parsing algorithms assume more importance for grammars having more substantial phrase structure components , such as CLARE ( which although employing some HPSG-like analyses still contains several tens of rules ) and the ANLT ( which uses a formalism derived from GPSG ), since the more specific rule set can be used to control which unifications are performed .	S-9
BKG	In NL analysis , the syntactic information associated with lexical items makes top-down parsing less attractive than bottom-up ( e.g. CKY ),, although the latter is often augmented with top-down prediction to improve performance,,.	S-10
TXT	Sectiondescribes three unification-based parsers which are related to polynomial-complexity bottom-up CF parsing algorithms .	S-11
TXT	Although incorporating unification increases their complexity to exponential on grammar size and input length ( section) , this appears to have little impact on practical performance ( section) .	S-12
TXT	Sectionsanddiscuss these findings and present conclusions .	S-13
OTH	The three parsers in this study are : a bottom-up left-corner parser , a ( non-deterministic ) LR parser , and an LR-like parser based on an algorithm devised by.	S-14
OTH	All three parsers accept grammars written in the ANLT formalism, and the first two are distributed as part of the ANLT package .	S-15
OTH	The parsers create parse foreststhat incorporate subtree sharing ( in which identical sub-analyses are shared between differing superordinate analyses ) and node packing ( where sub-analyses covering the same portion of input whose root categories are in a subsumption relationship are merged into a single node ) .	S-16
OTH	The bottom-up left-corner ( BU-LC ) parser operates left-to-right and breadth-first , storing partial ( active ) constituents in a chart ;gives a full description .	S-17
OTH	Although pure bottom-up parsing is not usually thought of as providing high performance , the actual implementation achieves very good throughput ( see section) due to a number of significant optimisations , amongst which are :	S-18
OTH	Efficient rule invocation from cheap ( static ) rule indexing , using discrimination trees keyed on the feature values in each rule 's first daughter to interleave rule access with unification and also to share unification results across groups of rules .	S-19
OTH	Dynamic indexing of partial and complete constituents on category types to avoid attempting unification or subsumption operations which static analysis shows will always fail .	S-20
OTH	Dynamic storage minimisation , deferring structure copying -- e.g. required by the unification operation or by constituent creation -- until absolutely necessary ( e.g. unification success or parse success , respectively ) .	S-21
OTH	The optimisations improve throughput by a factor of more than three .	S-22
OTH	describe a methodology for constructing an LR parser for a unification-based grammar , in which a CF ` backbone ' grammar is automatically constructed from the unification grammar , a parse table is constructed from the backbone grammar , and a parser is driven by the table and further controlled by unification of the ` residue ' of features in the unification grammar that are not encoded in the backbone .	S-23
OTH	In this parser , the LALR(1) techniqueis used , in conjunction with a graph-structured stack, adapting for unification-based parsing's- like recogniser that achieves polynomial complexity on input length through caching .	S-24
OTH	On each reduction the parser performs the unifications specified by the unification grammar version of the CF backbone rule being applied .	S-25
OTH	This constitutes an on-line parsing algorithm .	S-26
OTH	In the general case , the off-line variant ( in which all unifications are deferred until the complete CF parse forest has been constructed ) is not guaranteed to terminate ; indeed , it usually does not do so with the ANLT grammar .	S-27
OTH	However , a drawback to the on-line algorithm is that a variant of's caching cannot be used , since the cache must necessarily assume that all reductions at a given vertex with all rules with the same number of daughters build exactly the same constituent every time ; in general this is not the case when the daughters are unification categories .	S-28
OTH	A weaker kind of cache on partial analyses ( and thus unification results ) was found to be necessary in the implementation , though , to avoid duplication of unifications ; this sped the parser up by a factor of about three , at little space cost .	S-29
OTH	The Compiled -( CE ) parser is based on a predictive chart-based CF parsing algorithm devised bywhich is driven by a table compiling out the predictive component of's parser .	S-30
OTH	The size of the table is related linearly to the size of the grammar ( unlike the LR technique ) .	S-31
OTH	demonstrates that this parser always takes fewer steps than's , although its time complexity is the same :.	S-32
OTH	The space complexity is also cubic , since the parser uses's representation of parse forests .	S-33
OWN	The incorporation of unification into the CE parser follows the methodology developed for unification-based LR parsing described in the previous section : a table is computed from a CF ` backbone ' , and a parser , augmented with on-line unification and feature-based subsumption operations , is driven by the table .	S-34
OWN	To allow meaningful comparison with the LR parser , the CE parser uses a one-word lookahead version of the table , constructed using a modified LALR technique.	S-35
OWN	To achieve the cubic time bound , the parser must be able to retrieve in unit time all items in the chart having a given state , and start and end position in the input string .	S-36
OWN	However , the obvious array implementation , for say a ten word sentence with the ANLT grammar , would contain almost 500000 elements .	S-37
OWN	For this reason , the implementation employs a sparse representation for the array , since only a small proportion of the elements are ever filled .	S-38
OWN	In this parser , the same sort of duplication of unifications occurs as in the LR parser , so lists of partial analyses are cached in the same way .	S-39
BKG	The two variables that determine a parser 's computational complexity are the grammar and the input string.	S-40
TXT	These are considered separately in the next two sections .	S-41
OTH	The term dependent on the grammar in the time complexity of the BU-LC unification-based parser described above is, whereis the number of categories implicit in the grammar , and, the number of rules .	S-42
OTH	The space complexity is dominated by the size of the parse forest ,( these results are proved by) .	S-43
OTH	For the ANLT grammar , in which features are nested to a maximum depth of two ,is finite but nevertheless extremely large.	S-44
CTR	The grammar-dependent complexity of the LR parser makes it also appear intractable :shows that the number of LR(0) states for certain ( pathological ) grammars is exponentially related to the size of the grammar , and that there are some inputs which force an LR parser to visit all of these states in the course of a parse .	S-45
CTR	Thus the total number of operations performed , and also space consumed ( by the vertices in the graph-structured stack ) , is an exponential function of the size of the grammar .	S-46
OWN	To avoid this complexity , the CE parser employs a table construction method which ensures that the number of states in the parse table is linearly related to the size of the grammar , resulting in the number of operations performed by the parser being at worst a polynomial function of grammar size .	S-47
BKG	Although the complexity of returning all parses for a string is always related exponentially to its length ( since the number of parses is exponential , and they must all at least be enumerated ) , the complexity of a parser is usually measured for the computation of a parse forest ( unless extracting a single analysis from the forest is worse than linear ) .	S-48
OWN	If one of the features of the ANLT grammar formalism , the kleene operator ( allowing indefinite repetition of rule daughters ) , is disallowed , then the complexity of the BU-LC parser with respect to the length of the input string is, whereis the maximum number of daughters in a rule.	S-49
OWN	The inclusion of the operator increases the complexity to exponential .	S-50
OWN	To retain the polynomial time bound , new rules can be introduced to produce recursive tree structures instead of an iterated flat tree structure .	S-51
OWN	However , when this technique is applied to the ANLT grammar the increased overheads in rule invocation and structure building actually slow the parser down .	S-52
OWN	Although the time and space complexities of CF versions of the LR and CE parsers are, the unification versions of these parsers both turn out to have time bounds that are greater than cubic , in the general case .	S-53
OWN	The CF versions implicitly pack identical sequences of sub-analyses , and in all reductions at a given point with rules with the same number of daughters , the packed sequences can be formed into higher-level constituents as they stand without further processing .	S-54
OWN	However , in the unification versions , on each reduce action the daughters of the rule involved have to be unified with every possible alternative sequence of the sub-analyses that are being consumed by the rule ( in effect expanding and flattening out the packed sequences ) , leading to a bound ofon the total number of unifications .	S-55
AIM	To assess the practical performance of the three unification-based parsers described above , a series of experiments were conducted using the ANLT grammar, a wide-coverage grammar of English .	S-56
OWN	The grammar is defined in metagrammatical formalism which is compiled into a unification-based ` object grammar ' -- a syntactic variant of the Definite Clause Grammar formalism-- containing 84 features and 782 phrase structure rules .	S-57
OWN	Parsing uses fixed-arity term unification .	S-58
OWN	The grammar provides full coverage of the following constructions : declarative sentences , imperatives and questions ( yes / no , tag and wh-questions ) ; all unbounded dependency types ( topicalisation , relativisation , wh-questions ) ; a relatively exhaustive treatment of verb and adjective complement types ; phrasal and prepositional verbs of many complement types ; passivisation ; verb phrase extraposition ; sentence and verb phrase modification ; noun phrase complements and pre - and post-modification ; partitives ; coordination of all major category types ; and nominal and adjectival comparatives .	S-59
OWN	Although the grammar is linked to a lexicon containing definitions for 40000 base forms of words , the experiments draw on a much smaller lexicon of 600 words ( consisting of closed class vocabulary and , for open-class vocabulary , definitions of just a sample of words which taken together exhibit the full range of possible complementation patterns ) , since issues of lexical coverage are of no concern here .	S-60
OWN	In the first experiment , the ANLT grammar was loaded and a set of sentences was input to each of the three parsers .	S-61
OWN	In order to provide an independent basis for comparison , the same sentences were also input to the SRI Core Language Engine ( CLE ) parserwith the CLARE2.5 grammar, a state-of-the-art system accessible to the author .	S-62
OWN	The sentences were taken from an initial sample of 175 representative sentences extracted from a corpus of approximately 1500 that form part of the ANLT package .	S-63
OWN	This corpus , implicitly defining the types of construction the grammar is intended to cover , was written by the linguist who developed the ANLT grammar and is used to check for any adverse effects on coverage when the grammar is modified during grammar development .	S-64
OWN	Of the initial 175 sentences , the CLARE2.5 grammar failed to parse 42 ( in several cases because punctuation is strictly required but is missing from the corpus ) .	S-65
OWN	The ANLT grammar also failed to parse three of these , plus an additional four .	S-66
OWN	These sentences were removed from the sample , leaving 129 ( mean length 6.7 words ) of which 47 were declarative sentences , 38 wh-questions and other sentences with gaps , 20 passives , and 24 sentences containing co-ordination .	S-67
OWN	Tableshows the total parse times and storage allocated for the BU-LC parser , the LR parser , and the CE parser , all with ANLT grammar and lexicon .	S-68
OWN	All three parsers have been implemented by the author to a similar high standard : similar implementation techniques are used in all the parsers , the parsers share the same unification module , run in the same Lisp environment , have been compiled with the same optimisation settings , and have all been profiled with the same tools and hand-optimised to a similar extent .	S-69
OWN	( Thus any difference in performance of more than around 15 % is likely to stem from algorithmic rather than implementational reasons ) .	S-70
OWN	Both of the predictive parsers employ one symbol of lookahead , incorporated into the parsing tables by the LALR technique .	S-71
OWN	Tablealso shows the results for the CLE parser with the CLARE2.5 grammar and lexicon .	S-72
OWN	The figures include garbage collection time , and phrasal ( where appropriate ) processing , but not parse forest unpacking .	S-73
OWN	Both grammars give a total of around 280 analyses at a similar level of detail .	S-74
OWN	The results show that the LR parser is approximately 35 % faster than the BU-LC parser , and allocates about 30 % less storage .	S-75
OWN	The magnitude of the speed-up is less than might be expected , given the enthusiastic advocation of non-deterministic CF LR parsing for NL by some researchers,, and in the light of improvements observed for predictive over pure bottom-up parsing.	S-76
OWN	However , on the assumption that incorrect prediction of gaps is the main avoidable source of performance degradation ( c.f.) , further investigation shows that the speed-up is near the maximum that is possible with the ANLT grammar ( around 50 % ) .	S-77
OWN	The throughput of the CE parser is half that of the LR parser , and also less than that of the BU-LC parser .	S-78
OWN	However , it is intermediate between the two in terms of storage allocated .	S-79
OWN	Part of the difference in performance between it and the LR parser is due to the fact that it performs around 15 % more unifications .	S-80
OWN	This might be expected since the corresponding finite state automaton is not determinised -- to avoid theoretical exponential time complexity on grammar size -- thus paying a price at run time .	S-81
OWN	Additional reasons for the relatively poor performance of the CE parser are the overheads involved in maintaining a sparse representation of the chart , and the fact that with the ANLT grammar it generates less `` densely packed '' parse forests , since its parse table , with 14 % more states ( though fewer actions ) than the LALR(1) table , encodes more contextual distinctions.	S-82
OWN	Given that the ANLT and CLARE2.5 grammars have broadly similar ( wide ) coverage and return very similar numbers of syntactic analyses for the same inputs , the significantly better throughput of the three parsers described in this paper over the CLE parser indicates that they do not contain any significant implementational deficiencies which would bias the results .	S-83
OWN	A second experiment was carried out with the CLE parser , in which the built-in grammar and lexicon were replaced by versions of the ANLT object grammar and lexical entries translated ( automatically ) into the CLE formalism .	S-84
OWN	( The reverse of this configuration , in which the CLARE2.5 grammar is translated into the ANLT formalism , is not possible since some central rules contain sequences of daughters specified by a single ` list ' variable , which has no counterpart in the ANLT and cannot directly be simulated ) .	S-85
OWN	The throughput of this configuration was only one fiftieth of that of the BU-LC parser .	S-86
OWN	The ANLT grammar contains more than five times as many rules than does the sentence-level portion of the CLARE2.5 grammar , and( personal communication ) points out that the CLE parser had not previously been run with a grammar containing such a large number of rules , in contrast to the ANLT parsers .	S-87
OWN	Although the mean sentence length in the first two experiments is much shorter than the 20 - 30 word length ( depending on genre etc. ) that is common in real texts , the test sentences cover a wide range of syntactic constructions and exhibit less constructional bias than would a set of sentences extracted at random from a single corpus .	S-88
OWN	However , to investigate performance on longer sentences and the relationship between sentence length and parse time , a further set of 100 sentences with lengths distributed uniformly between 13 and 30 words was created by hand by the author and added to the previous test data .	S-89
OWN	Tableshows the relationship between sentence length and mean parse time with the BU-LC and LR parsers .	S-90
OWN	In contrast to the results from the first experiment , the throughput of the LR parser is only 4 % better than that of the BU-LC parser for sentences of 13 - 27 words in length .	S-91
OWN	The former parses many sentences up to twice as fast , but a small proportion of the others are parsed almost twice as slowly .	S-92
OWN	As well as their wide variability with respect to the BU-LC parser , the absolute variability of the LR parse times is high ( reflected in large standard deviations ---- see Table) .	S-93
OWN	Most of the sentences for which LR performance is worse contain more than one occurrence of the passive construction : due to their length this is particularly the case for the group of sentences of 28 - 30 words with which the LR parser performed particularly badly .	S-94
OWN	However , it is likely that if the constraining power of the parse table were improved in this area the difference in throughput between LR and BU-LC would revert to nearer the 35 % figure seen in the first experiment .	S-95
OWN	The standard deviations for numbers of parses are also relatively large .	S-96
OWN	The maximum number of parses was 2736 for one 29-word sentence , but on the other hand some of even the longest sentences had fewer than ten parses .	S-97
OWN	( But note that since the time taken for parse forest unpacking is not included in parse times , the latter do not vary by such a large magnitude ) .	S-98
OWN	The results of this experiment are displayed graphically in Figure 1 , together with a quadratic function .	S-99
OWN	Comparison with the function suggests that , at least for the BU-LC parser , parse time is related roughly quadratically to input length .	S-100
CTR	In previous work with the ANLT, throughput with raw corpus data was worse than that observed in these experiments , though probably only by a constant factor .	S-101
OWN	This could be due to the fact that the vocabulary of the corpus concerned exhibits significantly higher lexical ambiguity ; however , for sentences taken from a specific corpus , constructional bias observed in a training phase could be exploited to improve performance.	S-102
OWN	All three of the parsers have theoretical worst-case complexities that are either exponential , or polynomial on grammar size but with an extremely large multiplier .	S-103
OWN	Despite this , in the practical experiments reported in the previous section the parsers achieve relatively good throughput with a general-purpose wide-coverage grammar of a natural language .	S-104
OWN	It therefore seems likely that grammars of the type considered in this paper ( i.e. with relatively detailed phrase structure components , but comparatively simple from a unification perspective ) , although realistic , do not bring the parsing algorithms involved anywhere near the worst-case complexity .	S-105
OWN	In the experiments , the CE technique results in a parser with worse performance than the normal LR technique .	S-106
OWN	Indeed , for the ANLT grammar , the number of states -- the term that the CE technique reduces from exponential to linear on the grammar size -- is actually smaller in the standard LALR(1) table .	S-107
OWN	This suggests that , when considering the complexity of parsers , the issue of parse table size is of minor importance for realistic NL grammars ( as long as an implementation represents the table compactly ) , and that improvements to complexity results with respect to grammar size , although interesting from a theoretical standpoint , may have little practical relevance for the processing of natural language .	S-108
OWN	Althoughclaims that the problem of exponential grammar complexity `` is particularly acute for natural language processing since in this context the input length is typically small ( 10 - 20 words ) and the grammar size very large ( hundreds or thousands of rules and symbols ) '' , the experiments indicate that , with a wide-coverage NL grammar , inputs of this length can be parsed quite quickly ; however , longer inputs ( of more than about 30 words in length ) -- which occur relatively frequently in written text -- are a problem .	S-109
OWN	Unless grammar size takes on proportionately much more significance for such longer inputs , which seems implausible , it appears that in fact the major problems do not lie in the area of grammar size , but in input length .	S-110
OWN	All three parsers have worst-case complexities that are exponential on input length .	S-111
OWN	This theoretical bound might suggest that parsing performance would be severely degraded on long sentences ; however , the relationship between length of sentence and parse time with the ANLT grammar and the sentences tested appears to be approximately only quadratic .	S-112
OWN	There are probably many reasons why performance is much better than the complexity results suggest , but the most important may be that :	S-113
OWN	kleene star is used only in a very limited context ( for the analysis of coordination ) ,	S-114
OWN	more than 90 % of the rules in the grammar have no more than two daughters , and	S-115
OWN	very few rules license both left and right recursion ( for instance of the sort that is typically used to analyse noun compounding , i.e.) .	S-116
OWN	Despite little apparent theoretical difference between the CLE and ANLT grammar formalisms , and the fact that no explicit or formal process of ` tuning ' parsers and grammars to perform well with each other has been carried out in either of the ANLT or CLARE systems , the results of the experiment comparing the performance of the respective parsers using the ANLT grammar suggests that the parallel development of the software and grammars that has occurred nevertheless appears to have caused this to happen automatically .	S-117
OWN	It therefore seems likely that implementational decisions and optimisations based on subtle properties of specific grammars can , and may very often be , more important than worst-case complexity when considering the practical performance of parsing algorithms .	S-118
BAS	The research reported is in a similar vein to that of , for example ,,, and, in that it relies on empirical results for the study and optimisation of parsing algorithms rather than on traditional techniques of complexity analysis .	S-119
OWN	The paper demonstrates that research in this area will have to rely on empirical data until complexity theory is developed to a point where it is sufficiently fine-grained and accurate to predict how the properties of individual unification-based grammars will interact with particular parsing algorithms to determine practical performance .	S-120
